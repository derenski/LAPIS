{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The LAPIS (Low-rank Approximation via Partially Imputed Svd) Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "echo": false,
    "message": false,
    "warning": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Matrix\n",
      "\n",
      "Loaded glmnet 3.0-2\n",
      "\n",
      "\n",
      "Loading required package: iterators\n",
      "\n",
      "Loading required package: parallel\n",
      "\n",
      "\n",
      "Attaching package: ‘reshape’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:Matrix’:\n",
      "\n",
      "    expand\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘plyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:reshape’:\n",
      "\n",
      "    rename, round_any\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:plyr’:\n",
      "\n",
      "    arrange, count, desc, failwith, id, mutate, rename, summarise,\n",
      "    summarize\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:reshape’:\n",
      "\n",
      "    rename\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "Registered S3 method overwritten by 'GGally':\n",
      "  method from   \n",
      "  +.gg   ggplot2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "library(ggplot2)\n",
    "library(LaplacesDemon)\n",
    "library(glmnet)\n",
    "library(foreach)\n",
    "library(doParallel)\n",
    "library(quadprog)\n",
    "library(openxlsx)\n",
    "library(reshape)\n",
    "library(plyr)\n",
    "library(dplyr)\n",
    "library(gsynth)\n",
    "max_available_clusters <- detectCores()-1\n",
    "  \n",
    "desired_clusters <- 20\n",
    "  \n",
    "cl <- makeCluster(min(c(max_available_clusters, desired_clusters)))\n",
    "\n",
    "registerDoParallel(cl)\n",
    " \n",
    "source('causal_inference_methods_code.R')\n",
    "\n",
    "\n",
    "mse_and_se_of_mse <- function(error_mat){\n",
    "  \n",
    "  squared_errors <- error_mat\n",
    "  \n",
    "  the_mse <- mean(squared_errors)\n",
    "  \n",
    "  se_mse <- sqrt((sd(squared_errors)^2)/prod(dim(squared_errors)))\n",
    "  \n",
    "  final_stuff <- c(the_mse, se_mse)\n",
    "  \n",
    "  names(final_stuff) <- c(\"mse\", \"se_mse\")\n",
    "  \n",
    "  return(final_stuff)\n",
    "  \n",
    "}\n",
    "\n",
    "quiet <- function(x) { \n",
    "  sink(tempfile()) \n",
    "  on.exit(sink()) \n",
    "  invisible(force(x)) \n",
    "} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params <- read.xlsx(\"parameters_and_descriptions.xlsx\", sheet = \"parameter_data\", rowNames=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "echo": false,
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "# 3729 = GOOD SEED\n",
    "\n",
    "set.seed(3729)\n",
    "\n",
    "number_of_L <- as.numeric(params[\"number_of_Ls\", ])\n",
    "\n",
    "draws_per_L <- as.numeric(params[\"draws_per_L\", ])\n",
    "\n",
    "N <- as.numeric(params[\"N\", ])\n",
    "\n",
    "N0 <- N-as.numeric(params[\"N1\", ])\n",
    "\n",
    "Time <- as.numeric(params[\"Time\", ])\n",
    "\n",
    "Time0 <- as.numeric(Time)-as.numeric(params[\"Time1\", ])\n",
    "\n",
    "R <- as.numeric(params[\"R\", ])\n",
    "\n",
    "rho_parameter <- as.numeric(params['rho_parameter', ])\n",
    "\n",
    "tau <- as.numeric(params['tau', ])\n",
    "\n",
    "sigma_squared <- as.numeric(params['sigma_squared', ])\n",
    "\n",
    "penalized <- as.logical(as.numeric(params['penalized', ]))\n",
    "\n",
    "exchangable <- as.logical(as.numeric(params['exchangable', ]))\n",
    "\n",
    "min_iter <- as.numeric(params['min_iter', ])\n",
    "\n",
    "max_iter <- as.numeric(params['max_iter', ])\n",
    "\n",
    "tolerance <- as.numeric(params['tolerance', ])\n",
    "\n",
    "error = params['error', ]\n",
    "\n",
    "df <- as.numeric(params['df', ])\n",
    "\n",
    "rank_estimation_method <- params['rank_estimation_method', ]\n",
    "\n",
    "L_scaling <- as.numeric(params['L_scaling', ])\n",
    "\n",
    "arg_max <- as.numeric(params['arg_max', ])\n",
    "  \n",
    "y_max <- as.numeric(params['y_max', ])\n",
    "  \n",
    "halfway_time <- as.numeric(params['halfway_time', ])\n",
    "\n",
    "cutoff <- as.numeric(params['cutoff', ])\n",
    "\n",
    "design <- params['design', ]\n",
    "\n",
    "lag_structure <- params['lag_structure', ]\n",
    "\n",
    "average_treatment_length <- min(as.numeric(params['average_treatment_length', ]), Time-Time0)\n",
    "\n",
    "max_lag <- as.numeric(params['max_lag', ])\n",
    "\n",
    "treatment_function <- list_of_functions[[params['treatment_effect_function', ]]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations\n",
    "\n",
    "## Parameters\n",
    "\n",
    "- Number of Ls: `r number_of_L`\n",
    "\n",
    "- Draws per L: `r draws_per_L`\n",
    "\n",
    "- Number of Units: `r N`\n",
    "\n",
    "- Number of Control Units: `r N0`\n",
    "\n",
    "- Number of Times: `r Time`\n",
    "\n",
    "- Number of pre-treatment Times: `r Time0`\n",
    "\n",
    "- Rank of L: `r R`\n",
    "\n",
    "- Autocorrelation Parameter: `r rho_parameter`\n",
    "\n",
    "- True Effect Size for Constant Effect: `r tau`\n",
    "\n",
    "- Error Type: `r error`\n",
    "\n",
    "- Error Variance (if Gaussian error): `r sigma_squared`\n",
    "\n",
    "- Degrees of freedom (if t-error): `r df`\n",
    "\n",
    "- Exchangable: `r exchangable`\n",
    "\n",
    "- Penalized: `r penalized`\n",
    "\n",
    "- Rank Estimation Method: `r rank_estimation_method`\n",
    "\n",
    "- Scaling for $L$: `r L_scaling`\n",
    "\n",
    "- Treatment Effect Type: `r params$treatment_effect_function`\n",
    "\n",
    "- Treatment Design: `r design`\n",
    "\n",
    "- Lag Structure (if using staggered adoption structure): `r lag_structure`\n",
    "\n",
    "- Average Treatment Length (if using staggered adoption structure, with random adoption): `r average_treatment_length`\n",
    "\n",
    "- Maximum lag: `r max_lag`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# LAPIS vs Competitors, Fixed Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "echo": false,
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Joining, by = c(\"id\", \"time\")\n",
      "\n",
      "Joining, by = c(\"id\", \"time\")\n",
      "\n",
      "Joining, by = c(\"id\", \"time\")\n",
      "\n",
      "Joining, by = c(\"id\", \"time\")\n",
      "\n",
      "Joining, by = c(\"id\", \"time\")\n",
      "\n",
      "Joining, by = c(\"id\", \"time\")\n",
      "\n",
      "Joining, by = c(\"id\", \"time\")\n",
      "\n",
      "Joining, by = c(\"id\", \"time\")\n",
      "\n",
      "Joining, by = c(\"id\", \"time\")\n",
      "\n",
      "Joining, by = c(\"id\", \"time\")\n",
      "\n",
      "Joining, by = c(\"id\", \"time\")\n",
      "\n",
      "Joining, by = c(\"id\", \"time\")\n",
      "\n",
      "Joining, by = c(\"id\", \"time\")\n",
      "\n",
      "Joining, by = c(\"id\", \"time\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if (design==\"staggered_adoption\"){ ## Come up with a way to vary the lag in the staggered structure\n",
    "  \n",
    "  if(lag_structure == \"random\"){\n",
    "    \n",
    "    ones_we_make <- c(rep(0, N0), pmin(rpois(N-N0, \n",
    "                                            lambda=average_treatment_length-1)+1, \n",
    "                                      min(max_lag*(N-N0), .8*Time)))\n",
    "    \n",
    "  }else if (lag_structure==\"constant\"){ ## Does not control T-T0\n",
    "    \n",
    "    ones_we_make <- c(rep(0, N0), pmin(max_lag*seq(1, (N-N0)), floor(.8*Time)))\n",
    "    \n",
    "  }\n",
    "\n",
    "}else if (design==\"block_treatment\"){\n",
    "  \n",
    "  ones_we_make <- c(rep(0, N0), rep(Time-Time0, N-N0))\n",
    "  \n",
    "}\n",
    "\n",
    "W <- W_maker(N=N, Time=Time, ones_per_row = ones_we_make)\n",
    "\n",
    "tau_matrix <- t(apply(W, MARGIN=1, FUN=treated_matrix_creator, \n",
    "                      f_of_t=treatment_function, arg_max=arg_max, \n",
    "                      y_max=y_max, halfway_time=halfway_time, cutoff=cutoff))\n",
    "\n",
    "treated_units <- as.numeric(which(apply(W, MARGIN=1, FUN = function(x) any(x==1))))\n",
    "  \n",
    "treatment_times <- as.numeric(which(apply(W, MARGIN=2, FUN = function(x) any(x==1))))\n",
    "\n",
    "delta_t <- treatment_function(treatment_times-(min(treatment_times)-1),\n",
    "                              arg_max=arg_max, \n",
    "                      y_max=y_max, halfway_time=halfway_time, cutoff=cutoff, value=tau)\n",
    "  \n",
    "prediction_error_matrix_did <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "\n",
    "prediction_error_matrix_sc <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "\n",
    "                                          \n",
    "prediction_error_matrix_gsynth <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)                                      \n",
    "                                          \n",
    "prediction_error_matrix_mc_nnm <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "\n",
    "prediction_error_matrix_sdid <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "                                          \n",
    "\n",
    "prediction_error_matrix_lapis <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "\n",
    "prediction_error_matrix_oracle <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "\n",
    "autocorrelation_matrix <- make_rho_mat(rho=rho_parameter, p=dim(W)[2])\n",
    "\n",
    "sig_to_noise_ratios <- c()\n",
    "\n",
    "for (i in 1:number_of_L){\n",
    "  \n",
    " # set.seed(3729)\n",
    "  \n",
    "  errors_this_L_did <- rep(NA, draws_per_L)\n",
    "  \n",
    "  errors_this_L_sc <- rep(NA, draws_per_L)\n",
    "  \n",
    "  errors_this_L_gsynth <- rep(NA, draws_per_L)  \n",
    "    \n",
    "  errors_this_L_mc_nnm <- rep(NA, draws_per_L)\n",
    "  \n",
    "  errors_this_L_sdid <- rep(NA, draws_per_L)\n",
    "  \n",
    "  errors_this_L_lapis <- rep(NA, draws_per_L)\n",
    "  \n",
    "  errors_this_L_oracle <- rep(NA, draws_per_L)\n",
    "  \n",
    "  if (exchangable){\n",
    "    \n",
    "    U_vec <- rexp(n=N*R, rate=1)\n",
    "\n",
    "    V_vec <- rexp(n=Time*R, rate=1)\n",
    "  \n",
    "    U <- matrix(U_vec, nrow=N, ncol=R, byrow=T)\n",
    "\n",
    "    V <- matrix(V_vec, nrow=Time, ncol=R, byrow=T)\n",
    "  \n",
    "  }else{\n",
    "    \n",
    "    U <- matrix(NA, nrow=N, ncol=R, byrow=T)\n",
    "\n",
    "    V <- matrix(NA, nrow=Time, ncol=R, byrow=T)\n",
    "    \n",
    "    for (row_unit in 1:N){\n",
    "      \n",
    "      U[row_unit,] <- rpois(n=R, lambda=sqrt(row_unit/N))\n",
    "      \n",
    "    } \n",
    "    \n",
    "    for (row_time in 1:Time){\n",
    "      \n",
    "      V[row_time,] <- rpois(n=R, lambda=sqrt(row_time/Time))\n",
    "      \n",
    "    }\n",
    "    \n",
    "  }\n",
    "\n",
    "  L <- L_scaling*(U %*% t(V))\n",
    "  \n",
    "  for (j in 1:draws_per_L){\n",
    "    \n",
    "    if (error == 'gaussian'){\n",
    "      \n",
    "      Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W, distribution='gaussian',\n",
    "                 scalar_sigma=sqrt(sigma_squared))\n",
    "      \n",
    "    } else if (error == 't'){\n",
    "    \n",
    "      Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W,\n",
    "                 distribution='t', scalar_sigma=sqrt(sigma_squared))\n",
    "    \n",
    "    } else if (error == 'poisson'){\n",
    "      \n",
    "      if (exchangable == F){\n",
    "      \n",
    "        L <- abs(L)+1\n",
    "        \n",
    "      }\n",
    "      \n",
    "      Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W,\n",
    "                 distribution='poisson', scalar_sigma=sqrt(sigma_squared))\n",
    "      \n",
    "    } else if (error == 'scaled_gamma'){\n",
    "      \n",
    "      if (exchangable == F){\n",
    "      \n",
    "        L <- abs(L)+1\n",
    "        \n",
    "      }\n",
    "      \n",
    "      Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W,\n",
    "                 distribution='scaled_gamma', scalar_sigma=sqrt(sigma_squared))\n",
    "      \n",
    "    }else if (error == 'exponential'){\n",
    "      \n",
    "      if (exchangable == F){\n",
    "      \n",
    "        L <- abs(L)+1\n",
    "        \n",
    "      }\n",
    "      \n",
    "      Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W,\n",
    "                 distribution='exponential', scalar_sigma=sqrt(sigma_squared))\n",
    "\n",
    "    }\n",
    "    \n",
    "    #estimated_rank <- rank_estimator(Y, W, num_iter=100, K=5, \n",
    "    #                      lambda_grid=c(0, 10^seq(-20, 0, 2)), \n",
    "    #                      method=\"threshold\")\n",
    "    \n",
    "    #Y_0_LAPIS <- LAPIS(Y, rank_threshold=estimated_rank,\n",
    "    #                                    min_iter=1, max_iter=max_iter,\n",
    "    #                                    tolerance=tolerance, W=W)\n",
    "    \n",
    "    \n",
    "    if (N-N0 > 1){\n",
    "    \n",
    "    treatment_subjects_averaged <- colMeans(Y[1:dim(Y)[1] > N0,])\n",
    "    \n",
    "    W_averaged <- colMeans(W[1:dim(W)[1] > N0,])\n",
    "    \n",
    "    new_Y <- rbind(Y[1:dim(Y)[1] <= N0,], treatment_subjects_averaged)\n",
    "    \n",
    "    new_W <- rbind(W[1:dim(Y)[1] <= N0,], W_averaged)\n",
    "    \n",
    "    } else {\n",
    "    \n",
    "      new_Y <- Y\n",
    "    \n",
    "      new_W <- W\n",
    "      \n",
    "      \n",
    "    }\n",
    "      \n",
    "    meltedD <- melt(W) \n",
    "\n",
    "    names(meltedD) <- c('id', 'time', 'treated')\n",
    "\n",
    "    meltedObservedData <- melt(Y)\n",
    "\n",
    "    names(meltedObservedData) <- c('id', 'time', 'value')\n",
    "\n",
    "    joinedDataForGsynth <- meltedD %>% inner_join(meltedObservedData)  \n",
    "      \n",
    "      \n",
    "    \n",
    "    tau_estimate_did <- DID(Y=Y, W=W)\n",
    "    \n",
    "    tau_estimate_sc <- synth_cont(Y=Y, W=W)\n",
    "    \n",
    "    tau_estimate_sdid <- SDID_general(Y=Y, W=W,\n",
    "                 iterations_for_coord_desc=100)\n",
    "      \n",
    "      \n",
    "    meltedD <- melt(W) \n",
    "\n",
    "    names(meltedD) <- c('id', 'time', 'treated')\n",
    "\n",
    "    meltedObservedData <- melt(Y)\n",
    "\n",
    "    names(meltedObservedData) <- c('id', 'time', 'value')\n",
    "\n",
    "    joinedDataForGsynth <- meltedD %>% inner_join(meltedObservedData)\n",
    "    \n",
    "    mc_nnm_info <- matrix_completion_causal(Y=Y, W=W, num_iter=1000, K=5, \n",
    "                            lambda_grid=c(10^seq(-4,2,1), seq(2,5,1)),\n",
    "                            tol=1e-04)\n",
    "    \n",
    "    L_mc_nnm <- mc_nnm_info$L_hat\n",
    "    \n",
    "    tau_estimate_mc_nnm <- treat.estimator(Y=Y, L.hat=L_mc_nnm, W=W)\n",
    "    \n",
    "    estFactors <- rankMatrix(mc_nnm_info$L_hat)[1]  \n",
    "      \n",
    "    gsynthInfo <- quiet(gsynth(value~treated, data=joinedDataForGsynth, index=c('id', 'time'), \n",
    "                         parallel = TRUE, r=estFactors))\n",
    "\n",
    "    gsynthContEst <- gsynthInfo$att\n",
    "    \n",
    "    if (design=='block_treatment'){\n",
    "      \n",
    "    tau_estimate_gsynth <- gsynthContEst[(Time0+1):Time]\n",
    "        \n",
    "        }else{\n",
    "                            \n",
    "    tau_estimate_gsynth <- gsynthContEst[\n",
    "        which(names(gsynthContEst)==1):length(gsynthContEst)]\n",
    "        \n",
    "    }\n",
    "    \n",
    "    tau_estimate_lapis <- LAPIS_with_rank_estimation(Y=Y, \n",
    "                           W=W, initial_rank=rankMatrix(mc_nnm_info$L_hat)[1],\n",
    "                           tolerance=tolerance, \n",
    "                           min_iter=min_iter, max_iter=max_iter,   \n",
    "                           mu_grid=NULL, warm_start=F, method = 'explicit_tau')\n",
    "    \n",
    "    tau_estimate_oracle <- treat.estimator(Y=Y, L.hat=L, W=W)\n",
    "    \n",
    "    # stopCluster(cl)\n",
    "    \n",
    "    # c(10^seq(-4,2,1), seq(2,5,1))\n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "    \n",
    "    # tau_estimate_mc_nnm\n",
    "    \n",
    "    ## Only oracle in the sense that we know L\n",
    "    \n",
    "    error_tau_sc <- mean(abs(tau_estimate_sc-delta_t)^2)\n",
    "      \n",
    "    error_tau_gsynth <- mean(abs(tau_estimate_gsynth-delta_t)^2)\n",
    "    \n",
    "    error_tau_did <- mean(abs(tau_estimate_did-delta_t)^2)\n",
    "    \n",
    "    error_tau_mc_nnm <- mean(abs(tau_estimate_mc_nnm-delta_t)^2)\n",
    "    \n",
    "    error_tau_sdid <- mean(abs(tau_estimate_sdid-delta_t)^2)\n",
    "    \n",
    "    error_tau_lapis <- mean(abs(tau_estimate_lapis-delta_t)^2)\n",
    "    \n",
    "    error_tau_oracle <- mean(abs(tau_estimate_oracle-delta_t)^2)\n",
    "\n",
    "    errors_this_L_did[j] <- error_tau_did\n",
    "    \n",
    "    errors_this_L_sc[j] <- error_tau_sc\n",
    "      \n",
    "    errors_this_L_gsynth[j] <- error_tau_gsynth\n",
    "    \n",
    "    errors_this_L_mc_nnm[j] <- error_tau_mc_nnm\n",
    "    \n",
    "    errors_this_L_sdid[j] <- error_tau_sdid\n",
    "    \n",
    "    errors_this_L_lapis[j] <- error_tau_lapis\n",
    "    \n",
    "    errors_this_L_oracle[j] <- error_tau_oracle\n",
    "\n",
    "  }\n",
    "  \n",
    "  prediction_error_matrix_did[i,] <- errors_this_L_did\n",
    "  \n",
    "  prediction_error_matrix_sc[i,] <- errors_this_L_sc\n",
    "    \n",
    "  prediction_error_matrix_gsynth[i,] <- errors_this_L_gsynth\n",
    "  \n",
    "  prediction_error_matrix_mc_nnm[i, ] <- errors_this_L_mc_nnm\n",
    "  \n",
    "  prediction_error_matrix_sdid[i,] <- errors_this_L_sdid\n",
    "  \n",
    "  prediction_error_matrix_lapis[i,] <- errors_this_L_lapis\n",
    "  \n",
    "  prediction_error_matrix_oracle[i,] <- errors_this_L_oracle\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "effect_plot <- (ggplot(NULL, aes(x=1:length(delta_t), y=delta_t)) \n",
    "                + geom_point() + theme_bw() + xlab(\"Time\") + ylab(\"Treatment Effect\")\n",
    "                +ggtitle(\"True Treatment Effect Over Time\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal to Noise Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false
   },
   "outputs": [],
   "source": [
    "svd(L)$d[R]/(svd(sigma_squared*autocorrelation_matrix)$d[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mse for DID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false
   },
   "outputs": [],
   "source": [
    "\n",
    "set.seed(3729) # 1166.899 \n",
    "\n",
    "mse_and_se_of_mse_did <- mse_and_se_of_mse(prediction_error_matrix_did)\n",
    "\n",
    "mse_and_se_of_mse_did[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se for mse for DID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "mse_and_se_of_mse_did[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### mse for SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false,
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mse_and_se_of_mse_sc <- mse_and_se_of_mse(prediction_error_matrix_sc)\n",
    "\n",
    "mse_and_se_of_mse_sc[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se for mse for SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false,
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "mse_and_se_of_mse_sc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE FOR Gsynth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_and_se_of_mse_gsynth <- mse_and_se_of_mse(prediction_error_matrix_gsynth)\n",
    "\n",
    "mse_and_se_of_mse_gsynth[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se for mse for Gsynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_and_se_of_mse_gsynth[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### mse for MC_NNM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "mse_and_se_of_mse_mc_nnm <- mse_and_se_of_mse(prediction_error_matrix_mc_nnm)\n",
    "\n",
    "mse_and_se_of_mse_mc_nnm[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se for mse for MC_NNM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false,
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "mse_and_se_of_mse_mc_nnm[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### mse for SDID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "mse_and_se_of_mse_sdid <- mse_and_se_of_mse(prediction_error_matrix_sdid)\n",
    "\n",
    "mse_and_se_of_mse_sdid[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se for mse for SDID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false,
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "mse_and_se_of_mse_sdid[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mse For LAPIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false
   },
   "outputs": [],
   "source": [
    "mse_and_se_of_mse_lapis <- mse_and_se_of_mse(prediction_error_matrix_lapis)\n",
    "\n",
    "mse_and_se_of_mse_lapis[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se for mse for LAPIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "mse_and_se_of_mse_lapis[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mse For Oracle (Perfect L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false
   },
   "outputs": [],
   "source": [
    "mse_and_se_of_mse_oracle <- mse_and_se_of_mse(prediction_error_matrix_oracle)\n",
    "\n",
    "mse_and_se_of_mse_oracle[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mse For Oracle (Perfect L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "mse_and_se_of_mse_oracle[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Bias vs Reduction in Variance due to Averaging\n",
    "\n",
    "For more general designs of $W$ (like the block design scheme considered here) we allow a block in the bottom right hand corner of $W$ to be non-zero. When implementing LAPIS, we have two competing effects on estimation: \n",
    "\n",
    "- The bias that's introduced by making more of the $Y_{ij}$s zero. \n",
    "\n",
    "- The help we get with estimating $\\tau$ by being able to average over cells (because we asmeane $tau$) is the same for all units and times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would appear that accurracy increases for estimating $\\tau$ to a point, and then decreases when the bias introduced by replacement of cells with $0$ in $Y$ becomes too great. \n",
    "\n",
    "# Influence of $N_{0}/N$ on Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "## Chunk 18\n",
    "\n",
    "all_N0s <- floor((c(5, seq(10, 90, 10), 98)/100)*N)\n",
    "\n",
    "mses_N0_did <- c()\n",
    "\n",
    "se_mses_N0_did <- c()\n",
    "\n",
    "mses_N0_gsynth <- c()\n",
    "\n",
    "se_mses_N0_gsynth <- c()\n",
    "\n",
    "mses_N0_sc<- c()\n",
    "\n",
    "se_mses_N0_sc <- c()\n",
    "\n",
    "mses_N0_mc_nnm <- c()\n",
    "\n",
    "se_mses_N0_mc_nnm <- c()\n",
    "\n",
    "mses_N0_sdid <- c()\n",
    "\n",
    "se_mses_N0_sdid <- c()\n",
    "\n",
    "mses_N0_lapis <- c()\n",
    "\n",
    "se_mses_N0_lapis <- c()\n",
    "\n",
    "mses_N0_oracle <- c()\n",
    "\n",
    "se_mses_N0_oracle <- c()\n",
    "\n",
    "the_N0_over_Ns <- c()\n",
    "\n",
    "for (this_N0 in all_N0s){ \n",
    "  \n",
    "  the_N0_over_Ns <- c(the_N0_over_Ns, this_N0/N)\n",
    "  \n",
    "  set.seed(3729)\n",
    "  \n",
    "  if (design==\"staggered_adoption\"){ ## Come up with a way to vary the lag in the staggered structure\n",
    "  \n",
    "  if(lag_structure == \"random\"){\n",
    "    \n",
    "    ones_we_make <- c(rep(0, this_N0), pmin(rpois(N-this_N0, \n",
    "                                            lambda=average_treatment_length-1)+1, \n",
    "                                      min(max_lag*(N-this_N0), .8*Time)))\n",
    "    \n",
    "  }else if (lag_structure==\"constant\"){ ## Does not control T-T0\n",
    "    \n",
    "    ones_we_make <- c(rep(0, this_N0), pmin(max_lag*seq(1, (N-this_N0)), floor(.8*Time)))\n",
    "    \n",
    "  }\n",
    "\n",
    "}else if (design==\"block_treatment\"){\n",
    "  \n",
    "  ones_we_make <- c(rep(0, this_N0), rep(Time-Time0, N-this_N0))\n",
    "  \n",
    "}\n",
    "  \n",
    "  W <- W_maker(N=N, Time=Time, ones_per_row = ones_we_make)\n",
    "\n",
    "  tau_matrix <- t(apply(W, MARGIN=1, FUN=treated_matrix_creator, \n",
    "                      f_of_t=treatment_function, arg_max=arg_max, \n",
    "                      y_max=y_max, halfway_time=halfway_time, cutoff=cutoff, \n",
    "                      value=tau))\n",
    "\n",
    "  treated_units <- as.numeric(which(apply(W, MARGIN=1, FUN = function(x) any(x==1))))\n",
    "  \n",
    "  treatment_times <- as.numeric(which(apply(W, MARGIN=2, FUN = function(x) any(x==1))))\n",
    "\n",
    "  delta_t <- treatment_function(treatment_times-(min(treatment_times)-1),\n",
    "                              arg_max=arg_max, \n",
    "                      y_max=y_max, halfway_time=halfway_time, cutoff=cutoff, value=tau)\n",
    "  \n",
    "  autocorrelation_matrix <- make_rho_mat(rho=rho_parameter, p=dim(W)[2])\n",
    "\n",
    "  prediction_error_matrix_did <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "  \n",
    "  prediction_error_matrix_sc <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "                                            \n",
    "  prediction_error_matrix_gsynth <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "  \n",
    "  prediction_error_matrix_mc_nnm <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "\n",
    "  prediction_error_matrix_sdid <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "\n",
    "  prediction_error_matrix_lapis <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "  \n",
    "  prediction_error_matrix_oracle <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    " \n",
    "  for (i in 1:number_of_L){\n",
    "  \n",
    " # set.seed(3729)\n",
    "  \n",
    "  errors_this_L_did <- rep(NA, draws_per_L)\n",
    "  \n",
    "  errors_this_L_sc <- rep(NA, draws_per_L)\n",
    "      \n",
    "  errors_this_L_gsynth <- rep(NA, draws_per_L)\n",
    "  \n",
    "  errors_this_L_mc_nnm <- rep(NA, draws_per_L)\n",
    "  \n",
    "  errors_this_L_sdid <- rep(NA, draws_per_L)\n",
    "  \n",
    "  errors_this_L_lapis <- rep(NA, draws_per_L)\n",
    "  \n",
    "  errors_this_L_oracle <- rep(NA, draws_per_L)\n",
    "  \n",
    "  if (exchangable){\n",
    "    \n",
    "    U_vec <- rexp(n=N*R, rate=1)\n",
    "\n",
    "    V_vec <- rexp(n=Time*R, rate=1)\n",
    "  \n",
    "    U <- matrix(U_vec, nrow=N, ncol=R, byrow=T)\n",
    "\n",
    "    V <- matrix(V_vec, nrow=Time, ncol=R, byrow=T)\n",
    "  \n",
    "  }else{\n",
    "    \n",
    "    U <- matrix(NA, nrow=N, ncol=R, byrow=T)\n",
    "\n",
    "    V <- matrix(NA, nrow=Time, ncol=R, byrow=T)\n",
    "    \n",
    "    for (row_unit in 1:N){\n",
    "      \n",
    "      U[row_unit,] <- rpois(n=R, lambda=sqrt(row_unit/N))\n",
    "      \n",
    "    } \n",
    "    \n",
    "    for (row_time in 1:Time){\n",
    "      \n",
    "      V[row_time,] <- rpois(n=R, lambda=sqrt(row_time/Time))\n",
    "      \n",
    "    }\n",
    "    \n",
    "  }\n",
    "\n",
    "  L <- L_scaling*(U %*% t(V))\n",
    "  \n",
    "  for (j in 1:draws_per_L){\n",
    "    \n",
    "    if (error == 'gaussian'){\n",
    "      \n",
    "      Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W, distribution='gaussian',\n",
    "                 scalar_sigma=sqrt(sigma_squared))\n",
    "      \n",
    "    } else if (error == 't'){\n",
    "    \n",
    "      Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W,\n",
    "                 distribution='t', scalar_sigma=sqrt(sigma_squared))\n",
    "    \n",
    "    } else if (error == 'poisson'){\n",
    "      \n",
    "      if (exchangable == F){\n",
    "      \n",
    "        L <- abs(L)+1\n",
    "        \n",
    "      }\n",
    "      \n",
    "      Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W,\n",
    "                 distribution='poisson', scalar_sigma=sqrt(sigma_squared))\n",
    "      \n",
    "    } else if (error == 'scaled_gamma'){\n",
    "      \n",
    "      if (exchangable == F){\n",
    "      \n",
    "        L <- abs(L)+1\n",
    "        \n",
    "      }\n",
    "      \n",
    "      Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W,\n",
    "                 distribution='scaled_gamma', scalar_sigma=sqrt(sigma_squared))\n",
    "      \n",
    "    }else if (error == 'exponential'){\n",
    "      \n",
    "      if (exchangable == F){\n",
    "      \n",
    "        L <- abs(L)+1\n",
    "        \n",
    "      }\n",
    "      \n",
    "      Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W,\n",
    "                 distribution='exponential', scalar_sigma=sqrt(sigma_squared))\n",
    "\n",
    "    }\n",
    "    \n",
    "    #estimated_rank <- rank_estimator(Y, W, num_iter=100, K=5, \n",
    "    #                      lambda_grid=c(0, 10^seq(-20, 0, 2)), \n",
    "    #                      method=\"threshold\")\n",
    "    \n",
    "    #Y_0_LAPIS <- LAPIS(Y, rank_threshold=estimated_rank,\n",
    "    #                                    min_iter=1, max_iter=max_iter,\n",
    "    #                                    tolerance=tolerance, W=W)\n",
    "    \n",
    "    \n",
    "    if (N-this_N0 > 1){\n",
    "    \n",
    "    treatment_subjects_averaged <- colMeans(Y[1:dim(Y)[1] > this_N0,])\n",
    "    \n",
    "    W_averaged <- colMeans(W[1:dim(W)[1] > this_N0,])\n",
    "    \n",
    "    new_Y <- rbind(Y[1:dim(Y)[1] <= this_N0,], treatment_subjects_averaged)\n",
    "    \n",
    "    new_W <- rbind(W[1:dim(Y)[1] <= this_N0,], W_averaged)\n",
    "    \n",
    "    } else {\n",
    "    \n",
    "      new_Y <- Y\n",
    "    \n",
    "      new_W <- W\n",
    "      \n",
    "      \n",
    "    }\n",
    "    \n",
    "    tau_estimate_did <- DID(Y=Y, W=W)\n",
    "    \n",
    "    tau_estimate_sc <- synth_cont(Y=Y, W=W)\n",
    "      \n",
    "      \n",
    "    meltedD <- melt(W) \n",
    "\n",
    "    names(meltedD) <- c('id', 'time', 'treated')\n",
    "\n",
    "    meltedObservedData <- melt(Y)\n",
    "\n",
    "    names(meltedObservedData) <- c('id', 'time', 'value')\n",
    "\n",
    "    joinedDataForGsynth <- meltedD %>% inner_join(meltedObservedData)                          \n",
    "\n",
    "    tau_estimate_sdid <- SDID_general(Y=Y, W=W,\n",
    "                 iterations_for_coord_desc=100)\n",
    "    \n",
    "    mc_nnm_info <- matrix_completion_causal(Y=Y, W=W, num_iter=1000, K=5, \n",
    "                            lambda_grid=c(10^seq(-4,2,1), seq(2,5,1)),\n",
    "                            tol=1e-04)\n",
    "    \n",
    "    L_mc_nnm <- mc_nnm_info$L_hat\n",
    "    \n",
    "    tau_estimate_mc_nnm <- treat.estimator(Y=Y, L.hat=L_mc_nnm, W=W)\n",
    "      \n",
    "      \n",
    "    estFactors <- rankMatrix(mc_nnm_info$L_hat)[1]  \n",
    "      \n",
    "    gsynthInfo <- gsynth(value~treated, data=joinedDataForGsynth, index=c('id', 'time'), \n",
    "                         parallel = TRUE, r=estFactors)\n",
    "\n",
    "    gsynthContEst <- gsynthInfo$att\n",
    "    \n",
    "    if (design=='block_treatment'){\n",
    "      \n",
    "    tau_estimate_gsynth <- gsynthContEst[(Time0+1):Time]\n",
    "        \n",
    "        }else{\n",
    "                            \n",
    "    tau_estimate_gsynth <- gsynthContEst[\n",
    "        which(names(gsynthContEst)==1):length(gsynthContEst)]\n",
    "        \n",
    "    }  \n",
    "    \n",
    "    tau_estimate_lapis <- LAPIS_with_rank_estimation(Y=Y, \n",
    "                           W=W, initial_rank=rankMatrix(mc_nnm_info$L_hat)[1],\n",
    "                           tolerance=tolerance, \n",
    "                           min_iter=min_iter, max_iter=max_iter,   \n",
    "                           mu_grid=NULL, warm_start=F, method = 'explicit_tau')\n",
    "    \n",
    "    tau_estimate_oracle <- treat.estimator(Y=Y, L.hat=L, W=W)\n",
    "    \n",
    "\n",
    "    \n",
    "    error_tau_sc <- mean(abs(tau_estimate_sc-delta_t)^2)\n",
    "      \n",
    "    error_tau_gsynth <- mean(abs(tau_estimate_gsynth-delta_t)^2)\n",
    "    \n",
    "    error_tau_did <- mean(abs(tau_estimate_did-delta_t)^2)\n",
    "    \n",
    "    error_tau_mc_nnm <- mean(abs(tau_estimate_mc_nnm-delta_t)^2)\n",
    "    \n",
    "    error_tau_sdid <- mean(abs(tau_estimate_sdid-delta_t)^2)\n",
    "    \n",
    "    error_tau_lapis <- mean(abs(tau_estimate_lapis-delta_t)^2)\n",
    "    \n",
    "    error_tau_oracle <- mean(abs(tau_estimate_oracle-delta_t)^2)\n",
    "\n",
    "    errors_this_L_did[j] <- error_tau_did\n",
    "    \n",
    "    errors_this_L_sc[j] <- error_tau_sc\n",
    "      \n",
    "    errors_this_L_gsynth[j] <- error_tau_gsynth\n",
    "    \n",
    "    errors_this_L_mc_nnm[j] <- error_tau_mc_nnm\n",
    "    \n",
    "    errors_this_L_sdid[j] <- error_tau_sdid\n",
    "    \n",
    "    errors_this_L_lapis[j] <- error_tau_lapis\n",
    "    \n",
    "    errors_this_L_oracle[j] <- error_tau_oracle\n",
    "\n",
    "  }\n",
    "  \n",
    "  prediction_error_matrix_did[i,] <- errors_this_L_did\n",
    "  \n",
    "  prediction_error_matrix_sc[i,] <- errors_this_L_sc\n",
    "      \n",
    "      \n",
    "  prediction_error_matrix_gsynth[i,] <- errors_this_L_gsynth\n",
    "  \n",
    "  prediction_error_matrix_mc_nnm[i, ] <- errors_this_L_mc_nnm\n",
    "  \n",
    "  prediction_error_matrix_sdid[i,] <- errors_this_L_sdid\n",
    "  \n",
    "  prediction_error_matrix_lapis[i,] <- errors_this_L_lapis\n",
    "  \n",
    "  prediction_error_matrix_oracle[i,] <- errors_this_L_oracle\n",
    "\n",
    "}\n",
    "  \n",
    "  \n",
    "    mse_and_se_of_mse_did <- mse_and_se_of_mse(prediction_error_matrix_did)\n",
    "    \n",
    "    mse_and_se_of_mse_sc <- mse_and_se_of_mse(prediction_error_matrix_sc)\n",
    "                                            \n",
    "    mse_and_se_of_mse_gsynth <- mse_and_se_of_mse(prediction_error_matrix_gsynth)\n",
    "    \n",
    "    mse_and_se_of_mse_mc_nnm <- mse_and_se_of_mse(prediction_error_matrix_mc_nnm)\n",
    "    \n",
    "    mse_and_se_of_mse_sdid <- mse_and_se_of_mse(prediction_error_matrix_sdid)\n",
    "    \n",
    "    mse_and_se_of_mse_lapis <- mse_and_se_of_mse(prediction_error_matrix_lapis)\n",
    "  \n",
    "    mse_and_se_of_mse_oracle <- mse_and_se_of_mse(prediction_error_matrix_oracle)\n",
    "    \n",
    "    mses_N0_did <- c(mses_N0_did, mse_and_se_of_mse_did[1])\n",
    "    \n",
    "    se_mses_N0_did <- c(se_mses_N0_did, mse_and_se_of_mse_did[2])\n",
    "    \n",
    "    mses_N0_sc <- c(mses_N0_sc, mse_and_se_of_mse_sc[1])\n",
    "    \n",
    "    se_mses_N0_sc <- c(se_mses_N0_sc, mse_and_se_of_mse_sc[2])\n",
    "                                            \n",
    "                                            \n",
    "    mses_N0_gsynth <- c(mses_N0_gsynth, mse_and_se_of_mse_gsynth[1])\n",
    "    \n",
    "    se_mses_N0_gsynth <- c(se_mses_N0_gsynth, mse_and_se_of_mse_gsynth[2])                                        \n",
    "    \n",
    "    mses_N0_mc_nnm <- c(mses_N0_mc_nnm, mse_and_se_of_mse_mc_nnm[1])\n",
    "    \n",
    "    se_mses_N0_mc_nnm <- c(se_mses_N0_mc_nnm, mse_and_se_of_mse_mc_nnm[2])\n",
    "    \n",
    "    mses_N0_sdid <- c(mses_N0_sdid, mse_and_se_of_mse_sdid[1])\n",
    "    \n",
    "    se_mses_N0_sdid <- c(se_mses_N0_sdid, mse_and_se_of_mse_sdid[2])\n",
    "    \n",
    "    mses_N0_lapis <- c(mses_N0_lapis, mse_and_se_of_mse_lapis[1])\n",
    "    \n",
    "    se_mses_N0_lapis <- c(se_mses_N0_lapis, mse_and_se_of_mse_lapis[2])\n",
    "    \n",
    "    mses_N0_oracle <- c(mses_N0_oracle, mse_and_se_of_mse_oracle[1])\n",
    "    \n",
    "    se_mses_N0_oracle <- c(se_mses_N0_oracle, mse_and_se_of_mse_oracle[2])\n",
    "\n",
    "}\n",
    "  \n",
    "  # mses_N0_mc_nnm, mses_N0_did, \n",
    "\n",
    "\n",
    "N0_data <- cbind(c( mses_N0_did, mses_N0_sc, mses_N0_gsynth, mses_N0_mc_nnm,\n",
    "              mses_N0_sdid, mses_N0_lapis, mses_N0_oracle),\n",
    "              \n",
    "             c(se_mses_N0_did, se_mses_N0_sc, se_mses_N0_gsynth, se_mses_N0_mc_nnm,\n",
    "              se_mses_N0_sdid, se_mses_N0_lapis, se_mses_N0_oracle)\n",
    "              \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "## mses_N0_mc_nnm, mses_N0_did,\n",
    "\n",
    "N0_sensitivity_data <- data.frame(rep(c('DID','SC', 'GSYNTH', \"MC-NNM\",'SDID', 'LAPIS',\n",
    "'ORACLE'), \n",
    "               each=length(mses_N0_lapis)))\n",
    "\n",
    "names(N0_sensitivity_data) <- 'Method'\n",
    "\n",
    "N0_sensitivity_data$N0 <- c(5, seq(10, 90, 10), 98)/100\n",
    "\n",
    "N0_sensitivity_data$mse <- N0_data[,1]\n",
    "\n",
    "N0_sensitivity_data$se <- N0_data[,2]\n",
    "\n",
    "p_mse_vs_N0 <- (ggplot(N0_sensitivity_data, aes(x=N0, y=sqrt(mse), col=Method)) + geom_line() + \n",
    "                   theme_bw()+ ggtitle(\"rmse as a Function of N0/N\") \n",
    "                +xlab(\"N0/N\"))\n",
    "\n",
    "#p_mse_vs_N0 <- (ggplot(N0_sensitivity_data, aes(x=N0, y=mse, col=Method)) + geom_line() + \n",
    "#                   geom_ribbon(aes(ymin=mse-1.9*se,\n",
    "#                   ymax=mse+1.9*se, alpha=.1), fill = \"grey70\", lty=2) +\n",
    "#                   theme_bw()+ ggtitle(\"Mse as a Function of N0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of $\\rho$ on Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false,
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "## Chunk 19\n",
    "\n",
    "signal_to_noise_ratios <- c()\n",
    "\n",
    "all_rhos <- seq(0, .95, .05)\n",
    "\n",
    "mses_rho_did <- c()\n",
    "\n",
    "se_mses_rho_did <- c()\n",
    "\n",
    "mses_rho_sc<- c()\n",
    "\n",
    "se_mses_rho_sc <- c()\n",
    "\n",
    "mses_rho_gsynth <- c()\n",
    "\n",
    "se_mses_rho_gsynth <- c()\n",
    "\n",
    "mses_rho_mc_nnm <- c()\n",
    "\n",
    "se_mses_rho_mc_nnm <- c()\n",
    "\n",
    "mses_rho_sdid <- c()\n",
    "\n",
    "se_mses_rho_sdid <- c()\n",
    "\n",
    "mses_rho_lapis <- c()\n",
    "\n",
    "se_mses_rho_lapis <- c()\n",
    "\n",
    "mses_rho_oracle <- c()\n",
    "\n",
    "se_mses_rho_oracle <- c()\n",
    "\n",
    "for (this_rho in all_rhos){ \n",
    "  \n",
    "  set.seed(3729)\n",
    "  \n",
    "  this_autocorrelation_matrix <- make_rho_mat(rho=this_rho, p=dim(W)[2])\n",
    "  \n",
    "  if (design==\"staggered_adoption\"){ ## Come up with a way to vary the lag in the staggered structure\n",
    "  \n",
    "  if(lag_structure == \"random\"){\n",
    "    \n",
    "    ones_we_make <- c(rep(0, N0), pmin(rpois(N-N0, \n",
    "                                            lambda=average_treatment_length-1)+1, \n",
    "                                      min(max_lag*(N-N0), .8*Time)))\n",
    "    \n",
    "  }else if (lag_structure==\"constant\"){ ## Does not control T-T0\n",
    "    \n",
    "    ones_we_make <- c(rep(0, N0), pmin(max_lag*seq(1, (N-N0)), floor(.8*Time)))\n",
    "    \n",
    "  }\n",
    "\n",
    "}else if (design==\"block_treatment\"){\n",
    "  \n",
    "  ones_we_make <- c(rep(0, N0), rep(Time-Time0, N-N0))\n",
    "  \n",
    "}\n",
    "\n",
    "  W <- W_maker(N=N, Time=Time, ones_per_row = ones_we_make)\n",
    "\n",
    "  tau_matrix <- t(apply(W, MARGIN=1, FUN=treated_matrix_creator, \n",
    "                      f_of_t=treatment_function, arg_max=arg_max, \n",
    "                      y_max=y_max, halfway_time=halfway_time, cutoff=cutoff,\n",
    "                      value=tau))\n",
    "\n",
    "  treated_units <- as.numeric(which(apply(W, MARGIN=1, FUN = function(x) any(x==1))))\n",
    "  \n",
    "  treatment_times <- as.numeric(which(apply(W, MARGIN=2, FUN = function(x) any(x==1))))\n",
    "\n",
    "  delta_t <- treatment_function(treatment_times-(min(treatment_times)-1),\n",
    "                              arg_max=arg_max, \n",
    "                      y_max=y_max, halfway_time=halfway_time, cutoff=cutoff, value=tau)\n",
    " \n",
    "  prediction_error_matrix_did <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "  \n",
    "  prediction_error_matrix_sc <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "  \n",
    "  prediction_error_matrix_mc_nnm <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "\n",
    "  prediction_error_matrix_sdid <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "\n",
    "  prediction_error_matrix_lapis <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "  \n",
    "  prediction_error_matrix_oracle <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "  \n",
    "  for (i in 1:number_of_L){\n",
    "  \n",
    " # set.seed(3729)\n",
    "  \n",
    "  errors_this_L_did <- rep(NA, draws_per_L)\n",
    "  \n",
    "  errors_this_L_sc <- rep(NA, draws_per_L)\n",
    "  \n",
    "  errors_this_L_mc_nnm <- rep(NA, draws_per_L)\n",
    "  \n",
    "  errors_this_L_sdid <- rep(NA, draws_per_L)\n",
    "  \n",
    "  errors_this_L_lapis <- rep(NA, draws_per_L)\n",
    "  \n",
    "  errors_this_L_oracle <- rep(NA, draws_per_L)\n",
    "  \n",
    "  if (exchangable){\n",
    "    \n",
    "    U_vec <- rexp(n=N*R, rate=1)\n",
    "\n",
    "    V_vec <- rexp(n=Time*R, rate=1)\n",
    "  \n",
    "    U <- matrix(U_vec, nrow=N, ncol=R, byrow=T)\n",
    "\n",
    "    V <- matrix(V_vec, nrow=Time, ncol=R, byrow=T)\n",
    "  \n",
    "  }else{\n",
    "    \n",
    "    U <- matrix(NA, nrow=N, ncol=R, byrow=T)\n",
    "\n",
    "    V <- matrix(NA, nrow=Time, ncol=R, byrow=T)\n",
    "    \n",
    "    for (row_unit in 1:N){\n",
    "      \n",
    "      U[row_unit,] <- rpois(n=R, lambda=sqrt(row_unit/N))\n",
    "      \n",
    "    } \n",
    "    \n",
    "    for (row_time in 1:Time){\n",
    "      \n",
    "      V[row_time,] <- rpois(n=R, lambda=sqrt(row_time/Time))\n",
    "      \n",
    "    }\n",
    "    \n",
    "  }\n",
    "\n",
    "  L <- L_scaling*(U %*% t(V))\n",
    "  \n",
    "  for (j in 1:draws_per_L){\n",
    "    \n",
    "    if (error == 'gaussian'){\n",
    "      \n",
    "      Y <- norta(number=N, corr_mat=this_autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W, distribution='gaussian',\n",
    "                 scalar_sigma=sqrt(sigma_squared))\n",
    "      \n",
    "    } else if (error == 't'){\n",
    "    \n",
    "      Y <- norta(number=N, corr_mat=this_autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W,\n",
    "                 distribution='t', scalar_sigma=sqrt(sigma_squared))\n",
    "    \n",
    "    } else if (error == 'poisson'){\n",
    "      \n",
    "      if (exchangable == F){\n",
    "      \n",
    "        L <- abs(L)+1\n",
    "        \n",
    "      }\n",
    "      \n",
    "      Y <- norta(number=N, corr_mat=this_autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W,\n",
    "                 distribution='poisson', scalar_sigma=sqrt(sigma_squared))\n",
    "      \n",
    "    } else if (error == 'scaled_gamma'){\n",
    "      \n",
    "      if (exchangable == F){\n",
    "      \n",
    "        L <- abs(L)+1\n",
    "        \n",
    "      }\n",
    "      \n",
    "      Y <- norta(number=N, corr_mat=this_autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W,\n",
    "                 distribution='scaled_gamma', scalar_sigma=sqrt(sigma_squared))\n",
    "      \n",
    "    }else if (error == 'exponential'){\n",
    "      \n",
    "      if (exchangable == F){\n",
    "      \n",
    "        L <- abs(L)+1\n",
    "        \n",
    "      }\n",
    "      \n",
    "      Y <- norta(number=N, corr_mat=this_autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W,\n",
    "                 distribution='exponential', scalar_sigma=sqrt(sigma_squared))\n",
    "\n",
    "    }\n",
    "    \n",
    "    #estimated_rank <- rank_estimator(Y, W, num_iter=100, K=5, \n",
    "    #                      lambda_grid=c(0, 10^seq(-20, 0, 2)), \n",
    "    #                      method=\"threshold\")\n",
    "    \n",
    "    #Y_0_LAPIS <- LAPIS(Y, rank_threshold=estimated_rank,\n",
    "    #                                    min_iter=1, max_iter=max_iter,\n",
    "    #                                    tolerance=tolerance, W=W)\n",
    "    \n",
    "    \n",
    "    if (N-N0 > 1){\n",
    "    \n",
    "    treatment_subjects_averaged <- colMeans(Y[1:dim(Y)[1] > N0,])\n",
    "    \n",
    "    W_averaged <- colMeans(W[1:dim(W)[1] > N0,])\n",
    "    \n",
    "    new_Y <- rbind(Y[1:dim(Y)[1] <= N0,], treatment_subjects_averaged)\n",
    "    \n",
    "    new_W <- rbind(W[1:dim(Y)[1] <= N0,], W_averaged)\n",
    "    \n",
    "    } else {\n",
    "    \n",
    "      new_Y <- Y\n",
    "    \n",
    "      new_W <- W\n",
    "      \n",
    "      \n",
    "    }\n",
    "    \n",
    "    tau_estimate_did <- DID(Y=Y, W=W)\n",
    "    \n",
    "    tau_estimate_sc <- synth_cont(Y=Y, W=W)\n",
    "      \n",
    "      \n",
    "    meltedD <- melt(W) \n",
    "\n",
    "    names(meltedD) <- c('id', 'time', 'treated')\n",
    "\n",
    "    meltedObservedData <- melt(Y)\n",
    "\n",
    "    names(meltedObservedData) <- c('id', 'time', 'value')\n",
    "\n",
    "    joinedDataForGsynth <- meltedD %>% inner_join(meltedObservedData)\n",
    "    \n",
    "    tau_estimate_sdid <- SDID_general(Y=Y, W=W,\n",
    "                 iterations_for_coord_desc=100)\n",
    "    \n",
    "    mc_nnm_info <- matrix_completion_causal(Y=Y, W=W, num_iter=1000, K=5, \n",
    "                            lambda_grid=c(10^seq(-4,2,1), seq(2,5,1)),\n",
    "                            tol=1e-04)\n",
    "    \n",
    "    L_mc_nnm <- mc_nnm_info$L_hat\n",
    "    \n",
    "    tau_estimate_mc_nnm <- treat.estimator(Y=Y, L.hat=L_mc_nnm, W=W)\n",
    "      \n",
    "      \n",
    "    estFactors <- rankMatrix(mc_nnm_info$L_hat)[1]  \n",
    "      \n",
    "    gsynthInfo <- gsynth(value~treated, data=joinedDataForGsynth, \n",
    "                         index=c('id', 'time'), \n",
    "                         parallel = TRUE, r=estFactors)\n",
    "\n",
    "    gsynthContEst <- gsynthInfo$att\n",
    "    \n",
    "    if (design=='block_treatment'){\n",
    "      \n",
    "        tau_estimate_gsynth <- gsynthContEst[(Time0+1):Time]\n",
    "        \n",
    "        }else{\n",
    "                            \n",
    "        tau_estimate_gsynth <- gsynthContEst[\n",
    "        which(names(gsynthContEst)==1):length(gsynthContEst)]\n",
    "        \n",
    "    }\n",
    "    \n",
    "    tau_estimate_lapis <- LAPIS_with_rank_estimation(Y=Y, \n",
    "                           W=W, initial_rank=rankMatrix(mc_nnm_info$L_hat)[1],\n",
    "                           tolerance=tolerance, \n",
    "                           min_iter=min_iter, max_iter=max_iter,   \n",
    "                           mu_grid=NULL, warm_start=F, method = 'explicit_tau')\n",
    "    \n",
    "    tau_estimate_oracle <- treat.estimator(Y=Y, L.hat=L, W=W)\n",
    "    \n",
    "    ## Only oracle in the sense that we know L\n",
    "    \n",
    "    error_tau_sc <- mean(abs(tau_estimate_sc-delta_t)^2)\n",
    "    \n",
    "    error_tau_did <- mean(abs(tau_estimate_did-delta_t)^2)\n",
    "    \n",
    "    error_tau_mc_nnm <- mean(abs(tau_estimate_mc_nnm-delta_t)^2)\n",
    "    \n",
    "    error_tau_sdid <- mean(abs(tau_estimate_sdid-delta_t)^2)\n",
    "    \n",
    "    error_tau_lapis <- mean(abs(tau_estimate_lapis-delta_t)^2)\n",
    "    \n",
    "    error_tau_oracle <- mean(abs(tau_estimate_oracle-delta_t)^2)\n",
    "\n",
    "    errors_this_L_did[j] <- error_tau_did\n",
    "    \n",
    "    errors_this_L_sc[j] <- error_tau_sc\n",
    "    \n",
    "    errors_this_L_mc_nnm[j] <- error_tau_mc_nnm\n",
    "    \n",
    "    errors_this_L_sdid[j] <- error_tau_sdid\n",
    "    \n",
    "    errors_this_L_lapis[j] <- error_tau_lapis\n",
    "    \n",
    "    errors_this_L_oracle[j] <- error_tau_oracle\n",
    "\n",
    "  }\n",
    "  \n",
    "  prediction_error_matrix_did[i,] <- errors_this_L_did\n",
    "  \n",
    "  prediction_error_matrix_sc[i,] <- errors_this_L_sc\n",
    "  \n",
    "  prediction_error_matrix_mc_nnm[i, ] <- errors_this_L_mc_nnm\n",
    "  \n",
    "  prediction_error_matrix_sdid[i,] <- errors_this_L_sdid\n",
    "  \n",
    "  prediction_error_matrix_lapis[i,] <- errors_this_L_lapis\n",
    "  \n",
    "  prediction_error_matrix_oracle[i,] <- errors_this_L_oracle\n",
    "\n",
    "}\n",
    "  \n",
    "  \n",
    "    mse_and_se_of_mse_did <- mse_and_se_of_mse(prediction_error_matrix_did)\n",
    "    \n",
    "    mse_and_se_of_mse_sc <- mse_and_se_of_mse(prediction_error_matrix_sc)\n",
    "    \n",
    "    mse_and_se_of_mse_mc_nnm <- mse_and_se_of_mse(prediction_error_matrix_mc_nnm)\n",
    "    \n",
    "    mse_and_se_of_mse_sdid <- mse_and_se_of_mse(prediction_error_matrix_sdid)\n",
    "    \n",
    "    mse_and_se_of_mse_lapis <- mse_and_se_of_mse(prediction_error_matrix_lapis)\n",
    "  \n",
    "    mse_and_se_of_mse_oracle <- mse_and_se_of_mse(prediction_error_matrix_oracle)\n",
    "    \n",
    "    mses_rho_did <- c(mses_rho_did, mse_and_se_of_mse_did[1])\n",
    "    \n",
    "    se_mses_rho_did <- c(se_mses_rho_did, mse_and_se_of_mse_did[2])\n",
    "    \n",
    "    mses_rho_sc <- c(mses_rho_sc, mse_and_se_of_mse_sc[1])\n",
    "    \n",
    "    se_mses_rho_sc <- c(se_mses_rho_sc, mse_and_se_of_mse_sc[2])\n",
    "    \n",
    "    mses_rho_mc_nnm <- c(mses_rho_mc_nnm, mse_and_se_of_mse_mc_nnm[1])\n",
    "    \n",
    "    se_mses_rho_mc_nnm <- c(se_mses_rho_mc_nnm, mse_and_se_of_mse_mc_nnm[2])\n",
    "    \n",
    "    mses_rho_sdid <- c(mses_rho_sdid, mse_and_se_of_mse_sdid[1])\n",
    "    \n",
    "    se_mses_rho_sdid <- c(se_mses_rho_sdid, mse_and_se_of_mse_sdid[2])\n",
    "    \n",
    "    mses_rho_lapis <- c(mses_rho_lapis, mse_and_se_of_mse_lapis[1])\n",
    "    \n",
    "    se_mses_rho_lapis <- c(se_mses_rho_lapis, mse_and_se_of_mse_lapis[2])\n",
    "    \n",
    "    mses_rho_oracle <- c(mses_rho_oracle, mse_and_se_of_mse_oracle[1])\n",
    "    \n",
    "    se_mses_rho_oracle <- c(se_mses_rho_oracle, mse_and_se_of_mse_oracle[2])\n",
    "  \n",
    "  \n",
    "  \n",
    "  signal_to_noise_ratios <- c(signal_to_noise_ratios, (svd(L)$d[R]/                             svd(sigma_squared*this_autocorrelation_matrix)$d[1]))\n",
    "\n",
    "}\n",
    "  \n",
    "  \n",
    "\n",
    "# mses_rho_mc_nnm, mses_rho_did,\n",
    "\n",
    "rho_data <- cbind(c( mses_rho_did, mses_rho_sc, mses_rho_mc_nnm,\n",
    "              mses_rho_sdid, mses_rho_lapis, mses_rho_oracle),\n",
    "              \n",
    "             c(se_mses_rho_did, se_mses_rho_sc, se_mses_rho_mc_nnm,\n",
    "              se_mses_rho_sdid, se_mses_rho_lapis, se_mses_rho_oracle)\n",
    "              \n",
    ")\n",
    "\n",
    "\n",
    "# , 'MC_NNM', 'DID', \n",
    "  \n",
    "rho_sensitivity_data <- data.frame(rep(c('DID','SC', \"MC-NNM\",'SDID', 'LAPIS',\n",
    "'ORACLE'), \n",
    "               each=length(mses_rho_lapis)))\n",
    "\n",
    "names(rho_sensitivity_data) <- 'Method'\n",
    "\n",
    "rho_sensitivity_data$rho <- all_rhos\n",
    "\n",
    "rho_sensitivity_data$mse <- rho_data[,1]\n",
    "\n",
    "rho_sensitivity_data$se <- rho_data[,2]\n",
    "\n",
    "\n",
    "p_snr_vs_rho <- (ggplot(NULL, aes(x=all_rhos, y=signal_to_noise_ratios)) + geom_line() + theme_bw()+ ggtitle(\"SNR as a Function of the Correlation Parameter\"))\n",
    "\n",
    "p_mse_vs_rho <- (ggplot(rho_sensitivity_data, aes(x=rho, y=sqrt(mse), col=Method)) + geom_line() + xlab(\"rho\") + theme_bw()+ ggtitle(\"rmse as a Function of the Correlation Parameter\"))\n",
    "\n",
    "#p_mse_vs_rho <- (ggplot(rho_sensitivity_data, aes(x=rho, y=mse, col=Method)) + geom_line() + \n",
    "#                   geom_ribbon(aes(ymin=mse-1.9*se,\n",
    "#                   ymax=mse+1.9*se, alpha=.1), fill = \"grey70\", lty=2) +\n",
    "#                   theme_bw()+ ggtitle(\"mse as a Function of the Correlation Parameter\"))\n",
    "\n",
    "\n",
    "#p_mse_vs_rho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of $\\tau$ on Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false,
    "eval": false,
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "## Chunk 20\n",
    "\n",
    "mses_tau_did <- c()\n",
    "\n",
    "se_mses_tau_did <- c()\n",
    "\n",
    "mses_tau_sc<- c()\n",
    "\n",
    "se_mses_tau_sc <- c()\n",
    "\n",
    "mses_tau_gsynth <- c()\n",
    "\n",
    "se_mses_tau_gsynth <- c()\n",
    "\n",
    "mses_tau_mc_nnm <- c()\n",
    "\n",
    "se_mses_tau_mc_nnm <- c()\n",
    "\n",
    "mses_tau_sdid <- c()\n",
    "\n",
    "se_mses_tau_sdid <- c()\n",
    "\n",
    "mses_tau_lapis <- c()\n",
    "\n",
    "se_mses_tau_lapis <- c()\n",
    "\n",
    "mses_tau_oracle <- c()\n",
    "\n",
    "se_mses_tau_oracle <- c()\n",
    "\n",
    "all_taus <- seq(1, 30, 2)\n",
    "\n",
    "for (this_tau in all_taus){\n",
    "\n",
    "  set.seed(3729)\n",
    "  \n",
    "  if (design==\"staggered_adoption\"){ ## Come up with a way to vary the lag in the staggered structure\n",
    "  \n",
    "  if(lag_structure == \"random\"){\n",
    "    \n",
    "    ones_we_make <- c(rep(0, N0), pmin(rpois(N-N0, \n",
    "                                            lambda=average_treatment_length-1)+1, \n",
    "                                      min(max_lag*(N-N0), .8*Time)))\n",
    "    \n",
    "  }else if (lag_structure==\"constant\"){ ## Does not control T-T0\n",
    "    \n",
    "    ones_we_make <- c(rep(0, N0), pmin(max_lag*seq(1, (N-N0)), floor(.8*Time)))\n",
    "    \n",
    "  }\n",
    "\n",
    "}else if (design==\"block_treatment\"){\n",
    "  \n",
    "  ones_we_make <- c(rep(0, N0), rep(Time-Time0, N-N0))\n",
    "  \n",
    "}\n",
    "\n",
    "  W <- W_maker(N=N, Time=Time, ones_per_row = ones_we_make)\n",
    "\n",
    "  this_tau_matrix <- t(apply(W, MARGIN=1, FUN=treated_matrix_creator, f_of_t=delta_t_constant,\n",
    "                        value=this_tau))\n",
    "\n",
    "  treated_units <- as.numeric(which(apply(W, MARGIN=1, FUN = function(x) any(x==1))))\n",
    "  \n",
    "  treatment_times <- as.numeric(which(apply(W, MARGIN=2, FUN = function(x) any(x==1))))\n",
    "\n",
    "  delta_t <- delta_t_constant(treatment_times-(min(treatment_times)-1), value=this_tau)\n",
    "  \n",
    "  treated_units <- as.numeric(which(apply(W, MARGIN=1, FUN = function(x) any(x==1))))\n",
    "  \n",
    "  treatment_times <- as.numeric(which(apply(W, MARGIN=2, FUN = function(x) any(x==1))))\n",
    "  \n",
    "  prediction_error_matrix_did <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "  \n",
    "  prediction_error_matrix_sc <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "                                            \n",
    "  prediction_error_matrix_gsynth <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "  \n",
    "  prediction_error_matrix_mc_nnm <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "\n",
    "  prediction_error_matrix_sdid <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "\n",
    "  prediction_error_matrix_lapis <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "  \n",
    "  prediction_error_matrix_oracle <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "  \n",
    "  autocorrelation_matrix <- make_rho_mat(rho=rho_parameter, p=dim(W)[2])\n",
    "\n",
    "  \n",
    "  for (i in 1:number_of_L){\n",
    "    \n",
    "   # set.seed(3729)\n",
    "    \n",
    "    errors_this_L_did <- rep(NA, draws_per_L)\n",
    "    \n",
    "    errors_this_L_sc <- rep(NA, draws_per_L)\n",
    "      \n",
    "    errors_this_L_gsynth <- rep(NA, draws_per_L)\n",
    "    \n",
    "    errors_this_L_mc_nnm <- rep(NA, draws_per_L)\n",
    "    \n",
    "    errors_this_L_sdid <- rep(NA, draws_per_L)\n",
    "    \n",
    "    errors_this_L_lapis <- rep(NA, draws_per_L)\n",
    "    \n",
    "    errors_this_L_oracle <- rep(NA, draws_per_L)\n",
    "    \n",
    "    if (exchangable){\n",
    "      \n",
    "      U_vec <- rexp(n=N*R, rate=1)\n",
    "  \n",
    "      V_vec <- rexp(n=Time*R, rate=1)\n",
    "    \n",
    "      U <- matrix(U_vec, nrow=N, ncol=R, byrow=T)\n",
    "  \n",
    "      V <- matrix(V_vec, nrow=Time, ncol=R, byrow=T)\n",
    "    \n",
    "    }else{\n",
    "      \n",
    "      U <- matrix(NA, nrow=N, ncol=R, byrow=T)\n",
    "  \n",
    "      V <- matrix(NA, nrow=Time, ncol=R, byrow=T)\n",
    "      \n",
    "      for (row_unit in 1:N){\n",
    "        \n",
    "        U[row_unit,] <- rpois(n=R, lambda=sqrt(row_unit/N))\n",
    "        \n",
    "      } \n",
    "      \n",
    "      for (row_time in 1:Time){\n",
    "        \n",
    "        V[row_time,] <- rpois(n=R, lambda=sqrt(row_time/Time))\n",
    "        \n",
    "      }\n",
    "      \n",
    "    }\n",
    "  \n",
    "    L <- L_scaling*(U %*% t(V))\n",
    "    \n",
    "    for (j in 1:draws_per_L){\n",
    "      \n",
    "      if (error == 'gaussian'){\n",
    "        \n",
    "        Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                   desired_mean_matrix= L+this_tau_matrix*W, distribution='gaussian',\n",
    "                   scalar_sigma=sqrt(sigma_squared))\n",
    "        \n",
    "      } else if (error == 't'){\n",
    "      \n",
    "        Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                   desired_mean_matrix= L+this_tau_matrix*W,\n",
    "                   distribution='t', scalar_sigma=sqrt(sigma_squared))\n",
    "      \n",
    "      } else if (error == 'poisson'){\n",
    "        \n",
    "        if (exchangable == F){\n",
    "        \n",
    "          L <- abs(L)+1\n",
    "          \n",
    "        }\n",
    "        \n",
    "        Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                   desired_mean_matrix= L+this_tau_matrix*W,\n",
    "                   distribution='poisson', scalar_sigma=sqrt(sigma_squared))\n",
    "        \n",
    "      } else if (error == 'scaled_gamma'){\n",
    "        \n",
    "        if (exchangable == F){\n",
    "        \n",
    "          L <- abs(L)+1\n",
    "          \n",
    "        }\n",
    "        \n",
    "        Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                   desired_mean_matrix= L+this_tau_matrix*W,\n",
    "                   distribution='scaled_gamma', scalar_sigma=sqrt(sigma_squared))\n",
    "        \n",
    "      }else if (error == 'exponential'){\n",
    "        \n",
    "        if (exchangable == F){\n",
    "        \n",
    "          L <- abs(L)+1\n",
    "          \n",
    "        }\n",
    "        \n",
    "        Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                   desired_mean_matrix= L+this_tau_matrix*W,\n",
    "                   distribution='exponential', scalar_sigma=sqrt(sigma_squared))\n",
    "  \n",
    "      }\n",
    "      \n",
    "      #estimated_rank <- rank_estimator(Y, W, num_iter=100, K=5, \n",
    "      #                      lambda_grid=c(0, 10^seq(-20, 0, 2)), \n",
    "      #                      method=\"threshold\")\n",
    "      \n",
    "      #Y_0_LAPIS <- LAPIS(Y, rank_threshold=estimated_rank,\n",
    "      #                                    min_iter=1, max_iter=max_iter,\n",
    "      #                                    tolerance=tolerance, W=W)\n",
    "      \n",
    "      \n",
    "      if (N-N0 > 1){\n",
    "      \n",
    "      treatment_subjects_averaged <- colMeans(Y[1:dim(Y)[1] > N0,])\n",
    "      \n",
    "      W_averaged <- colMeans(W[1:dim(W)[1] > N0,])\n",
    "      \n",
    "      new_Y <- rbind(Y[1:dim(Y)[1] <= N0,], treatment_subjects_averaged)\n",
    "      \n",
    "      new_W <- rbind(W[1:dim(Y)[1] <= N0,], W_averaged)\n",
    "      \n",
    "      } else {\n",
    "      \n",
    "        new_Y <- Y\n",
    "      \n",
    "        new_W <- W\n",
    "        \n",
    "        \n",
    "      }\n",
    "      \n",
    "      tau_estimate_did <- DID(Y=Y, W=W)\n",
    "      \n",
    "      tau_estimate_sc <- synth_cont(Y=Y, W=W)\n",
    "        \n",
    "        \n",
    "     meltedD <- melt(W) \n",
    "\n",
    "    names(meltedD) <- c('id', 'time', 'treated')\n",
    "\n",
    "    meltedObservedData <- melt(Y)\n",
    "\n",
    "    names(meltedObservedData) <- c('id', 'time', 'value')\n",
    "\n",
    "    joinedDataForGsynth <- meltedD %>% inner_join(meltedObservedData)\n",
    "\n",
    "      tau_estimate_sdid <- SDID_general(Y=Y, W=W,\n",
    "                   iterations_for_coord_desc=100)\n",
    "      \n",
    "      mc_nnm_info <- matrix_completion_causal(Y=Y, W=W, num_iter=1000, K=5, \n",
    "                            lambda_grid=c(10^seq(-4,2,1), seq(2,5,1)),\n",
    "                            tol=1e-04)\n",
    "    \n",
    "    L_mc_nnm <- mc_nnm_info$L_hat\n",
    "    \n",
    "    tau_estimate_mc_nnm <- treat.estimator(Y=Y, L.hat=L_mc_nnm, W=W)\n",
    "        \n",
    "        \n",
    "    estFactors <- rankMatrix(mc_nnm_info$L_hat)[1]  \n",
    "      \n",
    "    gsynthInfo <- gsynth(value~treated, data=joinedDataForGsynth, \n",
    "                         index=c('id', 'time'), \n",
    "                         parallel = TRUE, r=estFactors)\n",
    "\n",
    "    gsynthContEst <- gsynthInfo$att\n",
    "    \n",
    "    if (design=='block_treatment'){\n",
    "      \n",
    "    tau_estimate_gsynth <- gsynthContEst[(Time0+1):Time]\n",
    "        \n",
    "        }else{\n",
    "                            \n",
    "    tau_estimate_gsynth <- gsynthContEst[\n",
    "        which(names(gsynthContEst)==1):length(gsynthContEst)]\n",
    "        \n",
    "    }\n",
    "    \n",
    "    tau_estimate_lapis <- LAPIS_with_rank_estimation(Y=Y, \n",
    "                           W=W, initial_rank=rankMatrix(mc_nnm_info$L_hat)[1],\n",
    "                           tolerance=tolerance, \n",
    "                           min_iter=min_iter, max_iter=max_iter,   \n",
    "                           mu_grid=NULL, warm_start=F, method = 'explicit_tau')\n",
    "    \n",
    "    \n",
    "    # tau_estimate_mc_nnm\n",
    "    \n",
    "    ## Only oracle in the sense that we know L\n",
    "    \n",
    "    tau_estimate_oracle <- treat.estimator(Y=Y, L.hat=L, W=W)\n",
    "      \n",
    "      \n",
    "      \n",
    "      error_tau_sc <- mean(abs(tau_estimate_sc-this_tau)^2)\n",
    "        \n",
    "      error_tau_gsynth <- mean(abs(tau_estimate_gsynth-this_tau)^2)\n",
    "      \n",
    "      error_tau_did <- mean(abs(tau_estimate_did-this_tau)^2)\n",
    "      \n",
    "      error_tau_mc_nnm <- mean(abs(tau_estimate_mc_nnm-this_tau)^2)\n",
    "      \n",
    "      error_tau_sdid <- mean(abs(tau_estimate_sdid-this_tau)^2)\n",
    "      \n",
    "      error_tau_lapis <- mean(abs(tau_estimate_lapis-this_tau)^2)\n",
    "      \n",
    "      error_tau_oracle <- mean(abs(tau_estimate_oracle-this_tau)^2)\n",
    "  \n",
    "      errors_this_L_did[j] <- error_tau_did\n",
    "      \n",
    "      errors_this_L_sc[j] <- error_tau_sc\n",
    "        \n",
    "      errors_this_L_gsynth[j] <- error_tau_gsynth\n",
    "      \n",
    "      errors_this_L_mc_nnm[j] <- error_tau_mc_nnm\n",
    "      \n",
    "      errors_this_L_sdid[j] <- error_tau_sdid\n",
    "      \n",
    "      errors_this_L_lapis[j] <- error_tau_lapis\n",
    "      \n",
    "      errors_this_L_oracle[j] <- error_tau_oracle\n",
    "  \n",
    "    }\n",
    "    \n",
    "    prediction_error_matrix_did[i,] <- errors_this_L_did\n",
    "    \n",
    "    prediction_error_matrix_sc[i,] <- errors_this_L_sc\n",
    "      \n",
    "    prediction_error_matrix_gsynth[i,] <- errors_this_L_gsynth\n",
    "    \n",
    "    prediction_error_matrix_mc_nnm[i, ] <- errors_this_L_mc_nnm\n",
    "    \n",
    "    prediction_error_matrix_sdid[i,] <- errors_this_L_sdid\n",
    "    \n",
    "    prediction_error_matrix_lapis[i,] <- errors_this_L_lapis\n",
    "    \n",
    "    prediction_error_matrix_oracle[i,] <- errors_this_L_oracle\n",
    "\n",
    "}\n",
    "\n",
    "    \n",
    "    mse_and_se_of_mse_did <- mse_and_se_of_mse(prediction_error_matrix_did)\n",
    "    \n",
    "    mse_and_se_of_mse_sc <- mse_and_se_of_mse(prediction_error_matrix_sc)\n",
    "                                            \n",
    "    mse_and_se_of_mse_gsynth <- mse_and_se_of_mse(prediction_error_matrix_gsynth)\n",
    "    \n",
    "    mse_and_se_of_mse_mc_nnm <- mse_and_se_of_mse(prediction_error_matrix_mc_nnm)\n",
    "    \n",
    "    mse_and_se_of_mse_sdid <- mse_and_se_of_mse(prediction_error_matrix_sdid)\n",
    "    \n",
    "    mse_and_se_of_mse_lapis <- mse_and_se_of_mse(prediction_error_matrix_lapis)\n",
    "  \n",
    "    mse_and_se_of_mse_oracle <- mse_and_se_of_mse(prediction_error_matrix_oracle)\n",
    "    \n",
    "    mses_tau_did <- c(mses_tau_did, mse_and_se_of_mse_did[1])\n",
    "    \n",
    "    se_mses_tau_did <- c(se_mses_tau_did, mse_and_se_of_mse_did[2])\n",
    "    \n",
    "    mses_tau_sc <- c(mses_tau_sc, mse_and_se_of_mse_sc[1])\n",
    "    \n",
    "    se_mses_tau_sc <- c(se_mses_tau_sc, mse_and_se_of_mse_sc[2])\n",
    "                                            \n",
    "                                            \n",
    "    mses_tau_gsynth <- c(mses_tau_gsynth, mse_and_se_of_mse_gsynth[1])\n",
    "    \n",
    "    se_mses_tau_gsynth <- c(se_mses_tau_gsynth, mse_and_se_of_mse_gsynth[2])\n",
    "    \n",
    "    mses_tau_mc_nnm <- c(mses_tau_mc_nnm, mse_and_se_of_mse_mc_nnm[1])\n",
    "    \n",
    "    se_mses_tau_mc_nnm <- c(se_mses_tau_mc_nnm, mse_and_se_of_mse_mc_nnm[2])\n",
    "    \n",
    "    mses_tau_sdid <- c(mses_tau_sdid, mse_and_se_of_mse_sdid[1])\n",
    "    \n",
    "    se_mses_tau_sdid <- c(se_mses_tau_sdid, mse_and_se_of_mse_sdid[2])\n",
    "    \n",
    "    mses_tau_lapis <- c(mses_tau_lapis, mse_and_se_of_mse_lapis[1])\n",
    "    \n",
    "    se_mses_tau_lapis <- c(se_mses_tau_lapis, mse_and_se_of_mse_lapis[2])\n",
    "    \n",
    "    mses_tau_oracle <- c(mses_tau_oracle, mse_and_se_of_mse_oracle[1])\n",
    "    \n",
    "    se_mses_tau_oracle <- c(se_mses_tau_oracle, mse_and_se_of_mse_oracle[2])\n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# mses_tau_mc_nnm, mses_tau_did,\n",
    "\n",
    "\n",
    "tau_data <- cbind(c( mses_tau_did, mses_tau_sc, mses_tau_gsynth, mses_tau_mc_nnm,\n",
    "              mses_tau_sdid, mses_tau_lapis, mses_tau_oracle),\n",
    "              \n",
    "             c(se_mses_tau_did, se_mses_tau_sc, se_mses_tau_gsynth, se_mses_tau_mc_nnm,\n",
    "              se_mses_tau_sdid, se_mses_tau_lapis, se_mses_tau_oracle)\n",
    "              \n",
    ")\n",
    "\n",
    "tau_sensitivity_data <- data.frame(rep(c('DID','SC', 'GSYNTH', \"MC-NNM\",'SDID', 'LAPIS',\n",
    "'ORACLE'), \n",
    "               each=length(mses_tau_lapis)))\n",
    "\n",
    "names(tau_sensitivity_data) <- 'Method'\n",
    "\n",
    "tau_sensitivity_data$tau <- all_taus\n",
    "\n",
    "tau_sensitivity_data$mse <- tau_data[,1]\n",
    "\n",
    "tau_sensitivity_data$se <- tau_data[,2]\n",
    "\n",
    "p_mse_vs_tau <- (ggplot(tau_sensitivity_data, aes(x=tau, y=sqrt(mse), col=Method)) + geom_line() +xlab(\"tau\") + theme_bw()+ ggtitle(\"rmse as a Function of the Effect Size\"))\n",
    "\n",
    "#p_mse_vs_tau <- (ggplot(tau_sensitivity_data, aes(x=tau, y=mse, col=Method)) + geom_line() + \n",
    "#                   geom_ribbon(aes(ymin=mse-1.9*se,\n",
    "#                   ymax=mse+1.9*se, alpha=.1), fill = \"grey70\", lty=2) +\n",
    "#                   theme_bw()+ ggtitle(\"mse as a Function of the Effect Size\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence True Rank on Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false,
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "## Chunk 21\n",
    "\n",
    "mses_rank_did <- c()\n",
    "\n",
    "se_mses_rank_did <- c()\n",
    "\n",
    "mses_rank_sc<- c()\n",
    "\n",
    "se_mses_rank_sc <- c()\n",
    "\n",
    "mses_rank_gsynth <- c()\n",
    "\n",
    "se_mses_rank_gsynth <- c()\n",
    "\n",
    "mses_rank_mc_nnm <- c()\n",
    "\n",
    "se_mses_rank_mc_nnm <- c()\n",
    "\n",
    "mses_rank_sdid <- c()\n",
    "\n",
    "se_mses_rank_sdid <- c()\n",
    "\n",
    "mses_rank_lapis <- c()\n",
    "\n",
    "se_mses_rank_lapis <- c()\n",
    "\n",
    "mses_rank_oracle <- c()\n",
    "\n",
    "se_mses_rank_oracle <- c()\n",
    "\n",
    "all_ranks <- seq(2, 20, 2)\n",
    "\n",
    "for (rank in all_ranks){\n",
    "  \n",
    "  set.seed(3729)\n",
    "  \n",
    "  if (design==\"staggered_adoption\"){ ## Come up with a way to vary the lag in the staggered structure\n",
    "  \n",
    "  if(lag_structure == \"random\"){\n",
    "    \n",
    "    ones_we_make <- c(rep(0, N0), pmin(rpois(N-N0, \n",
    "                                            lambda=average_treatment_length-1)+1, \n",
    "                                      min(max_lag*(N-N0), .8*Time)))\n",
    "    \n",
    "  }else if (lag_structure==\"constant\"){ ## Does not control T-T0\n",
    "    \n",
    "    ones_we_make <- c(rep(0, N0), pmin(max_lag*seq(1, (N-N0)), floor(.8*Time)))\n",
    "    \n",
    "  }\n",
    "\n",
    "}else if (design==\"block_treatment\"){\n",
    "  \n",
    "  ones_we_make <- c(rep(0, N0), rep(Time-Time0, N-N0))\n",
    "  \n",
    "}\n",
    "\n",
    "  W <- W_maker(N=N, Time=Time, ones_per_row = ones_we_make)\n",
    "\n",
    "  tau_matrix <- t(apply(W, MARGIN=1, FUN=treated_matrix_creator, \n",
    "                      f_of_t=treatment_function, arg_max=arg_max, \n",
    "                      y_max=y_max, halfway_time=halfway_time, cutoff=cutoff))\n",
    "\n",
    "  treated_units <- as.numeric(which(apply(W, MARGIN=1, FUN = function(x) any(x==1))))\n",
    "  \n",
    "  treatment_times <- as.numeric(which(apply(W, MARGIN=2, FUN = function(x) any(x==1))))\n",
    "\n",
    "  delta_t <- treatment_function(treatment_times-(min(treatment_times)-1),\n",
    "                              arg_max=arg_max, \n",
    "                      y_max=y_max, halfway_time=halfway_time, cutoff=cutoff, value=tau)\n",
    "  \n",
    "  prediction_error_matrix_did <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "  \n",
    "  prediction_error_matrix_sc <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "  \n",
    "  prediction_error_matrix_gsynth <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)                                          \n",
    "                                            \n",
    "  prediction_error_matrix_mc_nnm <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "\n",
    "  prediction_error_matrix_sdid <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "\n",
    "  prediction_error_matrix_lapis <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "  \n",
    "  prediction_error_matrix_oracle <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "  \n",
    "  autocorrelation_matrix <- make_rho_mat(rho=rho_parameter, p=dim(W)[2])\n",
    "  \n",
    "for (i in 1:number_of_L){\n",
    "    \n",
    "   # set.seed(3729)\n",
    "    \n",
    "    errors_this_L_did <- rep(NA, draws_per_L)\n",
    "    \n",
    "    errors_this_L_sc <- rep(NA, draws_per_L)\n",
    "    \n",
    "    errors_this_L_gsynth <- rep(NA, draws_per_L)\n",
    "    \n",
    "    errors_this_L_mc_nnm <- rep(NA, draws_per_L)\n",
    "    \n",
    "    errors_this_L_sdid <- rep(NA, draws_per_L)\n",
    "    \n",
    "    errors_this_L_lapis <- rep(NA, draws_per_L)\n",
    "    \n",
    "    errors_this_L_oracle <- rep(NA, draws_per_L)\n",
    "    \n",
    "    if (exchangable){\n",
    "      \n",
    "      U_vec <- rexp(n=N*R, rate=1)\n",
    "  \n",
    "      V_vec <- rexp(n=Time*R, rate=1)\n",
    "    \n",
    "      U <- matrix(U_vec, nrow=N, ncol=rank, byrow=T)\n",
    "  \n",
    "      V <- matrix(V_vec, nrow=Time, ncol=rank, byrow=T)\n",
    "    \n",
    "    }else{\n",
    "      \n",
    "      U <- matrix(NA, nrow=N, ncol=rank, byrow=T)\n",
    "  \n",
    "      V <- matrix(NA, nrow=Time, ncol=rank, byrow=T)\n",
    "      \n",
    "      for (row_unit in 1:N){\n",
    "        \n",
    "        U[row_unit,] <- rpois(n=rank, lambda=sqrt(row_unit/N))\n",
    "        \n",
    "      } \n",
    "      \n",
    "      for (row_time in 1:Time){\n",
    "        \n",
    "        V[row_time,] <- rpois(n=rank, lambda=sqrt(row_time/Time))\n",
    "        \n",
    "      }\n",
    "      \n",
    "    }\n",
    "  \n",
    "    L <- L_scaling*(U %*% t(V))\n",
    "    \n",
    "    for (j in 1:draws_per_L){\n",
    "      \n",
    "      if (error == 'gaussian'){\n",
    "        \n",
    "        Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                   desired_mean_matrix= L+tau*W, distribution='gaussian',\n",
    "                   scalar_sigma=sqrt(sigma_squared))\n",
    "        \n",
    "      } else if (error == 't'){\n",
    "      \n",
    "        Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                   desired_mean_matrix= L+tau*W,\n",
    "                   distribution='t', scalar_sigma=sqrt(sigma_squared))\n",
    "      \n",
    "      } else if (error == 'poisson'){\n",
    "        \n",
    "        if (exchangable == F){\n",
    "        \n",
    "          L <- abs(L)+1\n",
    "          \n",
    "        }\n",
    "        \n",
    "        Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                   desired_mean_matrix= L+tau*W,\n",
    "                   distribution='poisson', scalar_sigma=sqrt(sigma_squared))\n",
    "        \n",
    "      } else if (error == 'scaled_gamma'){\n",
    "        \n",
    "        if (exchangable == F){\n",
    "        \n",
    "          L <- abs(L)+1\n",
    "          \n",
    "        }\n",
    "        \n",
    "        Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                   desired_mean_matrix= L+tau*W,\n",
    "                   distribution='scaled_gamma', scalar_sigma=sqrt(sigma_squared))\n",
    "        \n",
    "      }else if (error == 'exponential'){\n",
    "        \n",
    "        if (exchangable == F){\n",
    "        \n",
    "          L <- abs(L)+1\n",
    "          \n",
    "        }\n",
    "        \n",
    "        Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                   desired_mean_matrix= L+tau*W,\n",
    "                   distribution='exponential', scalar_sigma=sqrt(sigma_squared))\n",
    "  \n",
    "      }\n",
    "      \n",
    "      #estimated_rank <- rank_estimator(Y, W, num_iter=100, K=5, \n",
    "      #                      lambda_grid=c(0, 10^seq(-20, 0, 2)), \n",
    "      #                      method=\"threshold\")\n",
    "      \n",
    "      #Y_0_LAPIS <- LAPIS(Y, rank_threshold=estimated_rank,\n",
    "      #                                    min_iter=1, max_iter=max_iter,\n",
    "      #                                    tolerance=tolerance, W=W)\n",
    "      \n",
    "      \n",
    "      if (N-N0 > 1){\n",
    "      \n",
    "      treatment_subjects_averaged <- colMeans(Y[1:dim(Y)[1] > N0,])\n",
    "      \n",
    "      W_averaged <- colMeans(W[1:dim(W)[1] > N0,])\n",
    "      \n",
    "      new_Y <- rbind(Y[1:dim(Y)[1] <= N0,], treatment_subjects_averaged)\n",
    "      \n",
    "      new_W <- rbind(W[1:dim(Y)[1] <= N0,], W_averaged)\n",
    "      \n",
    "      } else {\n",
    "      \n",
    "        new_Y <- Y\n",
    "      \n",
    "        new_W <- W\n",
    "        \n",
    "        \n",
    "      }\n",
    "      \n",
    "      tau_estimate_did <- DID(Y=Y, W=W)\n",
    "      \n",
    "      tau_estimate_sc <- synth_cont(Y=Y, W=W)\n",
    "        \n",
    "        \n",
    "        \n",
    "         meltedD <- melt(W) \n",
    "\n",
    "    names(meltedD) <- c('id', 'time', 'treated')\n",
    "\n",
    "    meltedObservedData <- melt(Y)\n",
    "\n",
    "    names(meltedObservedData) <- c('id', 'time', 'value')\n",
    "\n",
    "    joinedDataForGsynth <- meltedD %>% inner_join(meltedObservedData)       \n",
    "\n",
    "      tau_estimate_sdid <- SDID_general(Y=Y, W=W,\n",
    "                   iterations_for_coord_desc=100)\n",
    "      \n",
    "    mc_nnm_info <- matrix_completion_causal(Y=Y, W=W, num_iter=1000, K=5, \n",
    "                            lambda_grid=c(10^seq(-4,2,1), seq(2,5,1)),\n",
    "                            tol=1e-04)\n",
    "    \n",
    "    L_mc_nnm <- mc_nnm_info$L_hat\n",
    "    \n",
    "    tau_estimate_mc_nnm <- treat.estimator(Y=Y, L.hat=L_mc_nnm, W=W)\n",
    "        \n",
    "    estFactors <- rankMatrix(mc_nnm_info$L_hat)[1]  \n",
    "      \n",
    "    gsynthInfo <- gsynth(value~treated, data=joinedDataForGsynth, index=c('id', 'time'), \n",
    "                         parallel = TRUE, r=estFactors)\n",
    "\n",
    "    gsynthContEst <- gsynthInfo$att\n",
    "    \n",
    "    if (design=='block_treatment'){\n",
    "      \n",
    "        tau_estimate_gsynth <- gsynthContEst[(Time0+1):Time]\n",
    "        \n",
    "        }else{\n",
    "                            \n",
    "        tau_estimate_gsynth <- gsynthContEst[\n",
    "        which(names(gsynthContEst)==1):length(gsynthContEst)]\n",
    "        \n",
    "    }\n",
    "    \n",
    "    tau_estimate_lapis <- LAPIS_with_rank_estimation(Y=Y, \n",
    "                           W=W, initial_rank=rankMatrix(mc_nnm_info$L_hat)[1],\n",
    "                           tolerance=tolerance, \n",
    "                           min_iter=min_iter, max_iter=max_iter,   \n",
    "                           mu_grid=NULL, warm_start=F, method = 'explicit_tau')\n",
    "    \n",
    "    tau_estimate_oracle <- treat.estimator(Y=Y, L.hat=L, W=W)\n",
    "    \n",
    "    ## Only oracle in the sense that we know L\n",
    "      \n",
    "      \n",
    "      error_tau_sc <- mean(abs(tau_estimate_sc-delta_t)^2)\n",
    "        \n",
    "      error_tau_gsynth <- mean(abs(tau_estimate_gsynth-delta_t)^2)\n",
    "      \n",
    "      error_tau_did <- mean(abs(tau_estimate_did-delta_t)^2)\n",
    "      \n",
    "      error_tau_mc_nnm <- mean(abs(tau_estimate_mc_nnm-delta_t)^2)\n",
    "      \n",
    "      error_tau_sdid <- mean(abs(tau_estimate_sdid-delta_t)^2)\n",
    "      \n",
    "      error_tau_lapis <- mean(abs(tau_estimate_lapis-delta_t)^2)\n",
    "      \n",
    "      error_tau_oracle <- mean(abs(tau_estimate_oracle-delta_t)^2)\n",
    "  \n",
    "      errors_this_L_did[j] <- error_tau_did\n",
    "      \n",
    "      errors_this_L_sc[j] <- error_tau_sc\n",
    "        \n",
    "      errors_this_L_gsynth[j] <- error_tau_gsynth\n",
    "      \n",
    "      errors_this_L_mc_nnm[j] <- error_tau_mc_nnm\n",
    "      \n",
    "      errors_this_L_sdid[j] <- error_tau_sdid\n",
    "      \n",
    "      errors_this_L_lapis[j] <- error_tau_lapis\n",
    "      \n",
    "      errors_this_L_oracle[j] <- error_tau_oracle\n",
    "  \n",
    "    }\n",
    "    \n",
    "    prediction_error_matrix_did[i,] <- errors_this_L_did\n",
    "    \n",
    "    prediction_error_matrix_sc[i,] <- errors_this_L_sc\n",
    "    \n",
    "    prediction_error_matrix_gsynth[i,] <- errors_this_L_gsynth\n",
    "    \n",
    "    prediction_error_matrix_mc_nnm[i, ] <- errors_this_L_mc_nnm\n",
    "    \n",
    "    prediction_error_matrix_sdid[i,] <- errors_this_L_sdid\n",
    "    \n",
    "    prediction_error_matrix_lapis[i,] <- errors_this_L_lapis\n",
    "    \n",
    "    prediction_error_matrix_oracle[i,] <- errors_this_L_oracle\n",
    "\n",
    "}\n",
    "\n",
    "    \n",
    "    mse_and_se_of_mse_did <- mse_and_se_of_mse(prediction_error_matrix_did)\n",
    "    \n",
    "    mse_and_se_of_mse_sc <- mse_and_se_of_mse(prediction_error_matrix_sc)\n",
    "                                            \n",
    "    mse_and_se_of_mse_gsynth <- mse_and_se_of_mse(prediction_error_matrix_gsynth)\n",
    "    \n",
    "    mse_and_se_of_mse_mc_nnm <- mse_and_se_of_mse(prediction_error_matrix_mc_nnm)\n",
    "    \n",
    "    mse_and_se_of_mse_sdid <- mse_and_se_of_mse(prediction_error_matrix_sdid)\n",
    "    \n",
    "    mse_and_se_of_mse_lapis <- mse_and_se_of_mse(prediction_error_matrix_lapis)\n",
    "  \n",
    "    mse_and_se_of_mse_oracle <- mse_and_se_of_mse(prediction_error_matrix_oracle)\n",
    "    \n",
    "    mses_rank_did <- c(mses_rank_did, mse_and_se_of_mse_did[1])\n",
    "    \n",
    "    se_mses_rank_did <- c(se_mses_rank_did, mse_and_se_of_mse_did[2])\n",
    "    \n",
    "    mses_rank_sc <- c(mses_rank_sc, mse_and_se_of_mse_sc[1])\n",
    "    \n",
    "    se_mses_rank_sc <- c(se_mses_rank_sc, mse_and_se_of_mse_sc[2])\n",
    "                                            \n",
    "    mses_rank_gsynth <- c(mses_rank_gsynth, mse_and_se_of_mse_gsynth[1])\n",
    "    \n",
    "    se_mses_rank_sc <- c(se_mses_rank_gsynth, mse_and_se_of_mse_gsynth[2])\n",
    "    \n",
    "    mses_rank_mc_nnm <- c(mses_rank_mc_nnm, mse_and_se_of_mse_mc_nnm[1])\n",
    "    \n",
    "    se_mses_rank_mc_nnm <- c(se_mses_rank_mc_nnm, mse_and_se_of_mse_mc_nnm[2])\n",
    "    \n",
    "    mses_rank_sdid <- c(mses_rank_sdid, mse_and_se_of_mse_sdid[1])\n",
    "    \n",
    "    se_mses_rank_sdid <- c(se_mses_rank_sdid, mse_and_se_of_mse_sdid[2])\n",
    "    \n",
    "    mses_rank_lapis <- c(mses_rank_lapis, mse_and_se_of_mse_lapis[1])\n",
    "    \n",
    "    se_mses_rank_lapis <- c(se_mses_rank_lapis, mse_and_se_of_mse_lapis[2])\n",
    "    \n",
    "    mses_rank_oracle <- c(mses_rank_oracle, mse_and_se_of_mse_oracle[1])\n",
    "    \n",
    "    se_mses_rank_oracle <- c(se_mses_rank_oracle, mse_and_se_of_mse_oracle[2])\n",
    "    \n",
    "}\n",
    "\n",
    "rank_data <- cbind(c( mses_rank_did, mses_rank_sc, mses_rank_gsynth, mses_rank_mc_nnm,\n",
    "              mses_rank_sdid, mses_rank_lapis, mses_rank_oracle),\n",
    "              \n",
    "             c(se_mses_rank_did, se_mses_rank_sc, se_mses_rank_gsynth, se_mses_rank_mc_nnm,\n",
    "              se_mses_rank_sdid, se_mses_rank_lapis, se_mses_rank_oracle)\n",
    "              \n",
    ")\n",
    "\n",
    "\n",
    "rank_sensitivity_data <- data.frame(rep(c('DID','SC', \"GSYNTH\", \"MC-NNM\",'SDID', 'LAPIS',\n",
    "'ORACLE'), \n",
    "               each=length(mses_rank_lapis)))\n",
    "\n",
    "names(rank_sensitivity_data) <- 'Method'\n",
    "\n",
    "rank_sensitivity_data$rank <- all_ranks\n",
    "\n",
    "rank_sensitivity_data$mse <- rank_data[,1]\n",
    "\n",
    "rank_sensitivity_data$se <- rank_data[,2]\n",
    "\n",
    "p_mse_vs_rank <- (ggplot(rank_sensitivity_data, aes(x=rank, y=sqrt(mse), col=Method)) + geom_line() + theme_bw()+ ggtitle(\"rmse as a Function of the True Rank\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of Rank Error on Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false,
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "## Chunk 21\n",
    "\n",
    "# R+rank_error\n",
    "\n",
    "mses_rank_error_did <- c()\n",
    "\n",
    "se_mses_rank_error_did <- c()\n",
    "\n",
    "mses_rank_error_sc<- c()\n",
    "\n",
    "se_mses_rank_error_sc <- c()\n",
    "\n",
    "mses_rank_error_gsynth <- c()\n",
    "\n",
    "se_mses_rank_error_gsynth <- c()\n",
    "\n",
    "mses_rank_error_mc_nnm <- c()\n",
    "\n",
    "se_mses_rank_error_mc_nnm <- c()\n",
    "\n",
    "mses_rank_error_sdid <- c()\n",
    "\n",
    "se_mses_rank_error_sdid <- c()\n",
    "\n",
    "mses_rank_error_lapis <- c()\n",
    "\n",
    "se_mses_rank_error_lapis <- c()\n",
    "\n",
    "mses_rank_error_oracle <- c()\n",
    "\n",
    "se_mses_rank_error_oracle <- c()\n",
    "\n",
    "all_rank_errors <- seq(max(R-10, R-(R-1)), R+(10), 2)-R\n",
    "\n",
    "for (rank_error in all_rank_errors){\n",
    "  \n",
    "  print(rank_error)\n",
    "  \n",
    "  set.seed(3729)\n",
    "  \n",
    "  if (design==\"staggered_adoption\"){ ## Come up with a way to vary the lag in the staggered structure\n",
    "  \n",
    "  if(lag_structure == \"random\"){\n",
    "    \n",
    "    ones_we_make <- c(rep(0, N0), pmin(rpois(N-N0, \n",
    "                                            lambda=average_treatment_length-1)+1, \n",
    "                                      min(max_lag*(N-N0), .8*Time)))\n",
    "    \n",
    "  }else if (lag_structure==\"constant\"){ ## Does not control T-T0\n",
    "    \n",
    "    ones_we_make <- c(rep(0, N0), pmin(max_lag*seq(1, (N-N0)), floor(.8*Time)))\n",
    "    \n",
    "  }\n",
    "\n",
    "}else if (design==\"block_treatment\"){\n",
    "  \n",
    "  ones_we_make <- c(rep(0, N0), rep(Time-Time0, N-N0))\n",
    "  \n",
    "}\n",
    "\n",
    "  W <- W_maker(N=N, Time=Time, ones_per_row = ones_we_make)\n",
    "\n",
    "  tau_matrix <- t(apply(W, MARGIN=1, FUN=treated_matrix_creator, \n",
    "                      f_of_t=treatment_function, arg_max=arg_max, \n",
    "                      y_max=y_max, halfway_time=halfway_time, cutoff=cutoff))\n",
    "\n",
    "  treated_units <- as.numeric(which(apply(W, MARGIN=1, FUN = function(x) any(x==1))))\n",
    "  \n",
    "  treatment_times <- as.numeric(which(apply(W, MARGIN=2, FUN = function(x) any(x==1))))\n",
    "\n",
    "  delta_t <- treatment_function(treatment_times-(min(treatment_times)-1),\n",
    "                              arg_max=arg_max, \n",
    "                      y_max=y_max, halfway_time=halfway_time, cutoff=cutoff)\n",
    "  \n",
    "  prediction_error_matrix_did <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "  \n",
    "  prediction_error_matrix_sc <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "                                            \n",
    "  prediction_error_matrix_gsynth <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "  \n",
    "  prediction_error_matrix_mc_nnm <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "\n",
    "  prediction_error_matrix_sdid <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "\n",
    "  prediction_error_matrix_lapis <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "  \n",
    "  prediction_error_matrix_oracle <- matrix(NA, nrow=number_of_L, ncol=draws_per_L)\n",
    "  \n",
    "  autocorrelation_matrix <- make_rho_mat(rho=rho_parameter, p=dim(W)[2])\n",
    "  \n",
    "  for (i in 1:number_of_L){\n",
    "    \n",
    "    errors_this_L_did <- rep(NA, draws_per_L)\n",
    "  \n",
    "    errors_this_L_sc <- rep(NA, draws_per_L)\n",
    "      \n",
    "     errors_this_L_gsynth <- rep(NA, draws_per_L)\n",
    "  \n",
    "    errors_this_L_mc_nnm <- rep(NA, draws_per_L)\n",
    "  \n",
    "    errors_this_L_sdid <- rep(NA, draws_per_L)\n",
    "  \n",
    "    errors_this_L_lapis <- rep(NA, draws_per_L)\n",
    "    \n",
    "    errors_this_L_oracle <- rep(NA, draws_per_L)\n",
    "    \n",
    "    if (exchangable){\n",
    "      \n",
    "      U_vec <- rexp(n=N*R, rate=1)\n",
    "  \n",
    "      V_vec <- rexp(n=Time*R, rate=1)\n",
    "    \n",
    "      U <- matrix(U_vec, nrow=N, ncol=R, byrow=T)\n",
    "  \n",
    "      V <- matrix(V_vec, nrow=Time, ncol=R, byrow=T)\n",
    "    \n",
    "    }else{\n",
    "      \n",
    "      U <- matrix(NA, nrow=N, ncol=R, byrow=T)\n",
    "  \n",
    "      V <- matrix(NA, nrow=Time, ncol=R, byrow=T)\n",
    "      \n",
    "      for (row_unit in 1:N){\n",
    "        \n",
    "        U[row_unit,] <- rpois(n=R, lambda=sqrt(row_unit/N))\n",
    "        \n",
    "      } \n",
    "      \n",
    "      for (row_time in 1:Time){\n",
    "        \n",
    "        V[row_time,] <- rpois(n=R, lambda=sqrt(row_time/Time))\n",
    "        \n",
    "      }\n",
    "      \n",
    "    }\n",
    "  \n",
    "    L <- L_scaling*(U %*% t(V))\n",
    "    \n",
    "    for (j in 1:draws_per_L){\n",
    "      \n",
    "        if (error == 'gaussian'){\n",
    "      \n",
    "      Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W, distribution='gaussian',\n",
    "                 scalar_sigma=sqrt(sigma_squared))\n",
    "      \n",
    "    } else if (error == 't'){\n",
    "    \n",
    "      Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W,\n",
    "                 distribution='t', scalar_sigma=1, df=df)\n",
    "    \n",
    "    } else if (error == 'poisson'){\n",
    "      \n",
    "      if (exchangable == F){\n",
    "      \n",
    "        L <- abs(L)+1\n",
    "        \n",
    "      }\n",
    "      \n",
    "      Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W,\n",
    "                 distribution='poisson', scalar_sigma=1)\n",
    "      \n",
    "    } else if (error == 'scaled_gamma'){\n",
    "      \n",
    "      if (exchangable == F){\n",
    "      \n",
    "        L <- abs(L)+1\n",
    "        \n",
    "      }\n",
    "      \n",
    "      Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W,\n",
    "                 distribution='scaled_gamma', scalar_sigma=1)\n",
    "      \n",
    "    }else if (error == 'exponential'){\n",
    "      \n",
    "      if (exchangable == F){\n",
    "      \n",
    "        L <- abs(L)+1\n",
    "        \n",
    "      }\n",
    "      \n",
    "      Y <- norta(number=N, corr_mat=autocorrelation_matrix,\n",
    "                 desired_mean_matrix= L+tau_matrix*W,\n",
    "                 distribution='exponential', scalar_sigma=1)\n",
    "\n",
    "    }\n",
    "      \n",
    "   # estimated_rank <- rank_estimator(Y, W, num_iter=100, K=5, \n",
    "  #                        lambda_grid=c(0, 10^seq(-20, 0, 2)), \n",
    "  #                        method=\"threshold\")\n",
    "      # estimated_rank <- rank_estimator(Y, W, num_iter=100, K=5, \n",
    "    #                      lambda_grid=c(0, 10^seq(-20, 0, 2)), \n",
    "    #                      method=\"threshold\")\n",
    "      \n",
    "      \n",
    "    if (N-N0 > 1){\n",
    "    \n",
    "      treatment_subjects_averaged <- colMeans(Y[1:dim(Y)[1] > N0,])\n",
    "    \n",
    "      W_averaged <- colMeans(W[1:dim(W)[1] > N0,])\n",
    "    \n",
    "      new_Y <- rbind(Y[1:dim(Y)[1] <= N0,], treatment_subjects_averaged)\n",
    "    \n",
    "      new_W <- rbind(W[1:dim(Y)[1] <= N0,], W_averaged)\n",
    "    \n",
    "    } else {\n",
    "    \n",
    "      new_Y <- Y\n",
    "    \n",
    "      new_W <- W\n",
    "      \n",
    "      \n",
    "    }\n",
    "    \n",
    "    tau_estimate_did <- DID(Y=Y, W=W)\n",
    "    \n",
    "    tau_estimate_sc <- synth_cont(Y=Y, W=W)\n",
    "        \n",
    "     meltedD <- melt(W) \n",
    "\n",
    "    names(meltedD) <- c('id', 'time', 'treated')\n",
    "\n",
    "    meltedObservedData <- melt(Y)\n",
    "\n",
    "    names(meltedObservedData) <- c('id', 'time', 'value')\n",
    "\n",
    "    joinedDataForGsynth <- meltedD %>% inner_join(meltedObservedData)\n",
    "\n",
    "    tau_estimate_sdid <- SDID_general(Y=Y, W=W,\n",
    "                 iterations_for_coord_desc=100)\n",
    "    \n",
    "    mc_nnm_info <- matrix_completion_causal(Y=Y, W=W, num_iter=1000, K=5, \n",
    "                            lambda_grid=c(10^seq(-4,2,1), seq(2,5,1)),\n",
    "                            tol=1e-04)\n",
    "    \n",
    "    L_mc_nnm <- mc_nnm_info$L_hat\n",
    "    \n",
    "    tau_estimate_mc_nnm <- treat.estimator(Y=Y, L.hat=L_mc_nnm, W=W)\n",
    "    \n",
    "        \n",
    "    estFactors <- rankMatrix(mc_nnm_info$L_hat)[1]  \n",
    "      \n",
    "    gsynthInfo <- gsynth(value~treated, data=joinedDataForGsynth, index=c('id', 'time'), \n",
    "                         parallel = TRUE, r=estFactors)\n",
    "\n",
    "    gsynthContEst <- gsynthInfo$att\n",
    "    \n",
    "    if (design=='block_treatment'){\n",
    "      \n",
    "        tau_estimate_gsynth <- gsynthContEst[(Time0+1):Time]\n",
    "        \n",
    "        }else{\n",
    "                            \n",
    "        tau_estimate_gsynth <- gsynthContEst[\n",
    "            which(names(gsynthContEst)==1):length(gsynthContEst)]\n",
    "        \n",
    "    }\n",
    "    \n",
    "    tau_estimate_lapis <- LAPIS_with_rank_estimation(Y=Y, \n",
    "                           W=W, initial_rank=rankMatrix(mc_nnm_info$L_hat)[1],\n",
    "                           tolerance=tolerance, \n",
    "                           min_iter=min_iter, max_iter=max_iter,   \n",
    "                           mu_grid=NULL, warm_start=F, method = 'explicit_tau')\n",
    "    \n",
    "    tau_estimate_oracle <- treat.estimator(Y=Y, L.hat=L, W=W)\n",
    "    \n",
    "    \n",
    "    # tau_estimate_mc_nnm\n",
    "    \n",
    "    ## Only oracle in the sense that we know L\n",
    "    \n",
    "    \n",
    "    error_rank_error_sc <- mean(abs(tau_estimate_sc-delta_t)^2)\n",
    "        \n",
    "    error_rank_error_gsynth <- mean(abs(tau_estimate_gsynth-delta_t)^2)\n",
    "    \n",
    "    error_rank_error_did <- mean(abs(tau_estimate_did-delta_t)^2)\n",
    "    \n",
    "    error_rank_error_mc_nnm <- mean(abs(tau_estimate_mc_nnm-delta_t)^2)\n",
    "    \n",
    "    error_rank_error_sdid <- mean(abs(tau_estimate_sdid-delta_t)^2)\n",
    "    \n",
    "    error_rank_error_lapis <- mean(abs(tau_estimate_lapis-delta_t)^2)\n",
    "    \n",
    "    error_rank_error_oracle <- mean(abs(tau_estimate_oracle-delta_t)^2)\n",
    "\n",
    "    errors_this_L_did[j] <- error_rank_error_did\n",
    "    \n",
    "    errors_this_L_sc[j] <- error_rank_error_sc\n",
    "        \n",
    "    errors_this_L_gsynth[j] <- error_rank_error_gsynth\n",
    "    \n",
    "    errors_this_L_mc_nnm[j] <- error_rank_error_mc_nnm\n",
    "    \n",
    "    errors_this_L_sdid[j] <- error_rank_error_sdid\n",
    "    \n",
    "    errors_this_L_lapis[j] <- error_rank_error_lapis\n",
    "    \n",
    "    errors_this_L_oracle[j] <- error_rank_error_oracle\n",
    "\n",
    "    }\n",
    "  \n",
    "    prediction_error_matrix_did[i,] <- errors_this_L_did\n",
    "    \n",
    "    prediction_error_matrix_sc[i,] <- errors_this_L_sc\n",
    "    \n",
    "    prediction_error_matrix_gsynth[i,] <- errors_this_L_gsynth\n",
    "    \n",
    "    prediction_error_matrix_mc_nnm[i,] <- errors_this_L_mc_nnm\n",
    "    \n",
    "    prediction_error_matrix_sdid[i,] <- errors_this_L_sdid\n",
    "  \n",
    "    prediction_error_matrix_lapis[i,] <- errors_this_L_lapis\n",
    "    \n",
    "    prediction_error_matrix_oracle[i,] <- errors_this_L_oracle\n",
    "\n",
    "  }\n",
    "\n",
    "    \n",
    "    mse_and_se_of_mse_did <- mse_and_se_of_mse(prediction_error_matrix_did)\n",
    "    \n",
    "    mse_and_se_of_mse_sc <- mse_and_se_of_mse(prediction_error_matrix_sc)\n",
    "                                            \n",
    "    mse_and_se_of_mse_gsynth <- mse_and_se_of_mse(prediction_error_matrix_gsynth)\n",
    "    \n",
    "    mse_and_se_of_mse_mc_nnm <- mse_and_se_of_mse(prediction_error_matrix_mc_nnm)\n",
    "    \n",
    "    mse_and_se_of_mse_sdid <- mse_and_se_of_mse(prediction_error_matrix_sdid)\n",
    "    \n",
    "    mse_and_se_of_mse_lapis <- mse_and_se_of_mse(prediction_error_matrix_lapis)\n",
    "  \n",
    "    mse_and_se_of_mse_oracle <- mse_and_se_of_mse(prediction_error_matrix_oracle)\n",
    "    \n",
    "    mses_rank_error_did <- c(mses_rank_error_did, mse_and_se_of_mse_did[1])\n",
    "    \n",
    "    se_mses_rank_error_did <- c(se_mses_rank_error_did, mse_and_se_of_mse_did[2])\n",
    "    \n",
    "    mses_rank_error_sc <- c(mses_rank_error_sc, mse_and_se_of_mse_sc[1])\n",
    "    \n",
    "    se_mses_rank_error_sc <- c(se_mses_rank_error_sc, mse_and_se_of_mse_sc[2])\n",
    "                                            \n",
    "    mses_rank_error_gsynth <- c(mses_rank_error_gsynth, mse_and_se_of_mse_gsynth[1])\n",
    "    \n",
    "    se_mses_rank_error_gsynth <- c(se_mses_rank_error_gsynth, mse_and_se_of_mse_gsynth[2])\n",
    "    \n",
    "    mses_rank_error_mc_nnm <- c(mses_rank_error_mc_nnm, mse_and_se_of_mse_mc_nnm[1])\n",
    "    \n",
    "    se_mses_rank_error_mc_nnm <- c(se_mses_rank_error_mc_nnm, mse_and_se_of_mse_mc_nnm[2])\n",
    "    \n",
    "    mses_rank_error_sdid <- c(mses_rank_error_sdid, mse_and_se_of_mse_sdid[1])\n",
    "    \n",
    "    se_mses_rank_error_sdid <- c(se_mses_rank_error_sdid, mse_and_se_of_mse_sdid[2])\n",
    "    \n",
    "    mses_rank_error_lapis <- c(mses_rank_error_lapis, mse_and_se_of_mse_lapis[1])\n",
    "    \n",
    "    se_mses_rank_error_lapis <- c(se_mses_rank_error_lapis, mse_and_se_of_mse_lapis[2])\n",
    "    \n",
    "    mses_rank_error_oracle <- c(mses_rank_error_oracle, mse_and_se_of_mse_oracle[1])\n",
    "    \n",
    "    se_mses_rank_error_oracle <- c(se_mses_rank_error_oracle, mse_and_se_of_mse_oracle[2])\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "rank_error_data <- cbind(c( mses_rank_error_did, mses_rank_error_sc, mses_rank_error_gsynth,mses_rank_error_mc_nnm,\n",
    "              mses_rank_error_sdid, mses_rank_error_lapis, mses_rank_error_oracle),\n",
    "              \n",
    "             c(se_mses_rank_error_did, se_mses_rank_error_sc, se_mses_rank_error_gsynth, se_mses_rank_error_mc_nnm,\n",
    "              se_mses_rank_error_sdid, se_mses_rank_error_lapis, se_mses_rank_error_oracle)\n",
    "              \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "## mses_rank_error_mc_nnm, mses_rank_error_did,\n",
    "\n",
    "rank_error_sensitivity_data <- data.frame(rep(c('DID','SC', 'GSYNTH', \"MC-NNM\",'SDID', 'LAPIS',\n",
    "'ORACLE'), \n",
    "               each=length(mses_rank_error_lapis)))\n",
    "\n",
    "names(rank_error_sensitivity_data) <- 'Method'\n",
    "\n",
    "rank_error_sensitivity_data$rank_error <- all_rank_errors\n",
    "\n",
    "rank_error_sensitivity_data$mse <- rank_error_data[,1]\n",
    "\n",
    "rank_error_sensitivity_data$se <- rank_error_data[,2]\n",
    "\n",
    "p_mse_vs_rank_error <- (ggplot(rank_error_sensitivity_data, aes(x=rank_error, y=sqrt(mse), col=Method)) + geom_line() + \n",
    "                   theme_bw()+ ggtitle(\"rmse as a Function of the Initial Rank Error\"))\n",
    "\n",
    "#p_mse_vs_rank_error <- (ggplot(rank_error_sensitivity_data, aes(x=rank_error, y=mse, #col=Method)) + geom_ribbon(aes(ymin=mse-1.9*se, ymax=mse+1.9*se, alpha=.1), fill = \"grey70\", #lty=2)+ geom_line()  + theme_bw()+ ggtitle(\"mse as a Function of the Initial Rank Error\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false,
    "lines_to_next_cell": 2,
    "message": false
   },
   "outputs": [],
   "source": [
    "\n",
    "full_output_directory <- params$output_directory\n",
    "\n",
    "image_directory <- paste(full_output_directory, \"/simulation_plots\", sep=\"\")\n",
    "\n",
    "if (!dir.exists(image_directory)){\n",
    "\n",
    "dir.create(image_directory)\n",
    "  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false,
    "message": false
   },
   "outputs": [],
   "source": [
    "\n",
    "effect_plot\n",
    "\n",
    "\n",
    "if (exists(\"effect_plot\")){\n",
    "\n",
    "ggsave(paste(image_directory,'/effect_size_plot.pdf' , sep=''), effect_plot,\n",
    "       width=5, height=3)\n",
    "}\n",
    "\n",
    "if (exists(\"p_mse_vs_tau\")){\n",
    "\n",
    "ggsave(paste(image_directory,'/varied_tau.pdf' , sep=''), p_mse_vs_tau,\n",
    "       width=5, height=3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false,
    "message": false
   },
   "outputs": [],
   "source": [
    "if (exists(\"p_mse_vs_rho\")){\n",
    "  \n",
    "ggsave(paste(image_directory,'/varied_rho.pdf' , sep=''), p_mse_vs_rho,\n",
    "       width=5, height=3)\n",
    "  \n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "if (exists(\"p_snr_vs_rho\")){\n",
    "  \n",
    "ggsave(paste(image_directory,'/snr_vs_rho.pdf' , sep=''), p_snr_vs_rho,\n",
    "       width=5, height=3)\n",
    "  \n",
    "\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false
   },
   "outputs": [],
   "source": [
    "\n",
    "if (exists(\"p_mse_vs_block_size\")){\n",
    "\n",
    "ggsave(paste(image_directory,'/varied_block_size.pdf' , sep=''), p_mse_vs_block_size, width=5, height=3)\n",
    "  \n",
    "} \n",
    "\n",
    "if (exists(\"p_mse_vs_N0\")){\n",
    "\n",
    "ggsave(paste(image_directory,'/varied_N0.pdf' , sep=''), p_mse_vs_N0, width=5, height=3)\n",
    "  \n",
    "}\n",
    "\n",
    "if (exists(\"p_mse_vs_rank_error\")){\n",
    "\n",
    "ggsave(paste(image_directory,'/varied_rank_error.pdf' , sep=''), p_mse_vs_rank_error, width=5, height=3)\n",
    "  \n",
    "}\n",
    "\n",
    "if (exists(\"p_mse_vs_rank\")){\n",
    "\n",
    "ggsave(paste(image_directory,'/varied_rank.pdf' , sep=''), p_mse_vs_rank, width=5, height=3)\n",
    "  \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "echo": false,
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# write.table(L, file=\"fixed_L.txt\", row.names=FALSE, col.names=FALSE)\n",
    "\n",
    "stopCluster(cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "warning,message,echo,eval,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
